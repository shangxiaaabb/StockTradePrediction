{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a19b71-a828-48e9-8b6c-af670c4516e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateutil.parser as parser\n",
    "import math\n",
    "def read_stock_data(data_home, data_type, venue, year, month, day, ticker, is_filter):\n",
    "    '''\n",
    "    从sever中读取一只股票一天的数据\n",
    "    data_home:数据所在folder\n",
    "    data_type:类型\n",
    "    venue:交易所\n",
    "    is_filter:是否进行filter操作\n",
    "    '''\n",
    "\n",
    "    path = str(data_home) + '/' + str(data_type) + '/' + str(venue) + '/' + str(year) + '/' + str(\n",
    "        month) + '/' + str(day) + '/' + str(ticker) + '.' + str(venue)  # 读数据的路径\n",
    "\n",
    "    if (os.path.exists(path)):\n",
    "        data0 = open(path, 'r')\n",
    "        data1 = pd.read_csv(StringIO(data0.read()))\n",
    "        data = data1.loc[:, ['time', 'volume', 'current','a1_v','a1_p','b1_v','b1_p',]]\n",
    "        diff_df = data.loc[:, ['time', 'volume']].diff()  # 差分，求出每次交易的交易量、交易额\n",
    "        data.iloc[1:len(data['volume']), 1] = diff_df.iloc[1:len(data['volume']), 1] # 第0个为NaN,从第一个代替原数据的volume\n",
    "        data['current'] = data['current']/10000\n",
    "        data['spread'] = (data['a1_p'] - data['b1_p'])/(data['a1_p'] + data['b1_p'])  # 计算 spread\n",
    "        data['quote_imbalance'] = (data['b1_v'] - data['a1_v']) / (data['b1_v'] + data['a1_v'])\n",
    "        if is_filter == 0:  # 不filter数据的时候\n",
    "            return data\n",
    "        else:\n",
    "            quantile = np.percentile(data['volume'], 99.5)\n",
    "            quantile2 = np.percentile(data['volume'], 0.5) \n",
    "            data = data[(quantile2 <= data['volume']) & (data['volume'] <= quantile)]  \n",
    "            return data\n",
    "    else:\n",
    "        path = str(data_home) + '/' + str(data_type) + '/' + str(venue) + '/' + str(year) + '/' + str(\n",
    "            month) + '/' + str(day) + '/' + str(ticker) + '.' + str(venue) + '.gz'\n",
    "        with gzip.open(path, 'rb') as gf:\n",
    "            data1 = pd.read_csv(gf)\n",
    "        data = data1.loc[:, ['time', 'volume','current', 'a1_v','a1_p','b1_v','b1_p',]]\n",
    "        data['current'] = data['current']/10000\n",
    "        diff_df = data.loc[:, ['time', 'volume']].diff()  # 差分，求出每次交易的交易量、交易额\n",
    "        data.iloc[1:len(data['volume']), 1] = diff_df.iloc[1:len(data['volume']), 1] # 第0个为NaN,从第一个代替原数据的volume\n",
    "        data['quote_imbalance'] = (data['b1_v'] - data['a1_v']) / (data['b1_v'] + data['a1_v'])\n",
    "        if is_filter == 0:  # 不filter数据的时候\n",
    "            return data\n",
    "        else:\n",
    "            quantile = np.percentile(data['volume'], 99.5)\n",
    "            quantile2 = np.percentile(data['volume'], 0.5) \n",
    "            data = data[(quantile2 <= data['volume']) & (data['volume'] <= quantile)]  \n",
    "            return data\n",
    "def trans_date(date): \n",
    "    dates = []\n",
    "    for i in range(len(date)):\n",
    "        year = str(date[i])[0:4]\n",
    "        month = str(date[i])[4:6]\n",
    "        day = str(date[i])[6:8]\n",
    "        date_std = datetime.date(int(year), int(month), int(day)).isoformat()\n",
    "        dates.append(date_std)\n",
    "    return dates\n",
    "\n",
    "\n",
    "def trans_time(time):  \n",
    "    times = []\n",
    "    for i in range(len(time)):\n",
    "        hour = str(time[i])[8:10]\n",
    "        minute = str(time[i])[10:12]\n",
    "        second = str(time[i])[12:14]\n",
    "        time_std = datetime.time(int(hour), int(minute), int(second)).isoformat()\n",
    "        times.append(time_std)\n",
    "    return times\n",
    "\n",
    "\n",
    "\n",
    "def divide_bin(time, binnumber):  # 计算每条交易所属的bin number\n",
    "    '''\n",
    "    time:columns of time\n",
    "    '''\n",
    "    n = 237 / (binnumber - 1) * 60\n",
    "    bin_nums = []\n",
    "    for i in range(len(time)):\n",
    "        if datetime.datetime.strptime(time[i],\"%H:%M:%S\") < datetime.datetime.strptime(\"09:30:00\",\"%H:%M:%S\"):\n",
    "            bin_num = 0  # 交易发生在9：30之前，bin number为0\n",
    "        elif datetime.datetime.strptime(time[i],\"%H:%M:%S\")>datetime.datetime.strptime(\"15:00:00\",\"%H:%M:%S\"):\n",
    "            bin_num = binnumber+1\n",
    "        else:\n",
    "            starttime = parser.parse(datetime.time(9, 30, 0).isoformat())  # 开始时间设为9：30\n",
    "            endtime = parser.parse(time[i])  # 结束时间是该条数据的交易时间\n",
    "            s = (endtime - starttime).seconds  # 从开盘到现在的秒数\n",
    "            if s > -1 and s < 7201:  # 交易发生在9：30-11：30之前\n",
    "                bin_num = int((s - 0.5) // n) + 1  # 9：30之后的bin number从1开始\n",
    "            elif s > 12599 and s < 19801:  # 13:00-15:00\n",
    "                bin_num = int((s - 0.5 - 5400) // n)+1  # 去掉中间的90分钟\n",
    "            else:\n",
    "                bin_num = binnumber\n",
    "        bin_nums.append(bin_num)\n",
    "    return bin_nums\n",
    "\n",
    "    \n",
    "####### imbalance\n",
    "def cal_bin_volume(subdf, binnumber):\n",
    "    '''\n",
    "    subdf: data to be processed, DataFrame\n",
    "    return: DataFrame including one stock, ranked by bin number\n",
    "    '''\n",
    "\n",
    "    subdf = subdf[~subdf['bin_num'].isin([binnumber + 1])]  # Exclude rows with bin number binnumber+1\n",
    "    subdf = subdf[~subdf['bin_num'].isin([binnumber])]  # Exclude rows with bin number binnumber\n",
    "    subdf['current'].replace(0, float(\"NaN\"),inplace=True)\n",
    "    grouped = subdf.groupby(['date','bin_num'])\n",
    "    aggregated = grouped['current'].agg(['max', 'min', 'first', 'last']).reset_index()\n",
    "    \n",
    "    daily_volume = subdf['volume'].groupby(subdf['date']).sum().reset_index()  # Calculate total volume for each day\n",
    "    bin_volume = subdf['volume'].groupby([subdf['date'], subdf['bin_num']]).sum().reset_index()  # Calculate volume for each bin\n",
    "\n",
    "    df = pd.merge(daily_volume, bin_volume,how='outer', on='date')  # Merge daily_volume and bin_volume\n",
    "    \n",
    "    subdf1 = pd.merge(df, aggregated[['date', 'bin_num', 'max', 'min', 'first', 'last']], how='outer', on=['date','bin_num'])\n",
    "\n",
    "    \n",
    "    def exponential_weighted_average(numbers, alpha):\n",
    "        n = len(numbers)\n",
    "        weights = np.array([alpha ** (n - 1 - i) for i in range(n)])  # 使用倒序的权重计算\n",
    "        weighted_sum = np.sum(np.multiply(numbers, weights))\n",
    "        weight_sum = np.sum(weights)\n",
    "        ewma = weighted_sum / weight_sum\n",
    "        return ewma\n",
    "\n",
    "    imbalance = subdf['quote_imbalance'].groupby([subdf['date'], subdf['bin_num']]).apply(lambda x: exponential_weighted_average(x, 0.9)).reset_index()\n",
    "    subdf1 = pd.merge(subdf1,imbalance,how='outer',on=['date','bin_num'])\n",
    "    return subdf1\n",
    "\n",
    "\n",
    "def get_df(data_home, data_type, venue, year, month, day,ticker, bin_num, is_filter=0):\n",
    "    stock_data = read_stock_data(data_home, data_type, venue, year, month, day, ticker, is_filter=0)\n",
    "    stock_data = stock_data.reset_index(drop=True)\n",
    "    transdate = trans_date(stock_data['time'])\n",
    "    transtime = trans_time(stock_data['time'])\n",
    "    stock_data.loc[:, 'date'] = transdate  \n",
    "    stock_data.loc[:, 'timet'] = transtime\n",
    "    bin_nums = divide_bin(time=stock_data['timet'], binnumber=bin_num)\n",
    "    stock_data.loc[:, 'bin_num'] = bin_nums\n",
    "    vol_df = cal_bin_volume(subdf=stock_data, binnumber=bin_num)\n",
    "    vol_df = vol_df.rename(columns={'volume_x': 'daily_volume'})\n",
    "    vol_df = vol_df.rename(columns={'volume_y': 'bin_volume'})\n",
    "    vol_df['bin_volume'] = vol_df['bin_volume'].fillna(1)  # 空值用1填充\n",
    "    vol_df['daily_volume'] = vol_df['daily_volume'].fillna(method = 'bfill')  # 空值用向上填充\n",
    "    return vol_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f79021-6925-458e-9685-0fc8bb0e33b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stock_data_all(data_home, data_type, venue, start_date, end_date, ticker, bin_number, is_filter):\n",
    "    '''\n",
    "    读取一只股票所有日期的数据，from start_date to end_date\n",
    "    '''\n",
    "\n",
    "    data_concat = pd.DataFrame(columns=['date', 'daily_volume', 'bin_num', 'bin_volume'])\n",
    "\n",
    "    start_date1 = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date1 = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    interval_day = (end_date1-start_date1).days\n",
    "\n",
    "    ##遍历日期\n",
    "\n",
    "    for i in range(interval_day+1):\n",
    "        date = datetime.datetime.strptime(start_date,'%Y-%m-%d') + datetime.timedelta(days=i)\n",
    "\n",
    "        date2 = datetime.datetime.strftime(date, '%Y-%m-%d')\n",
    "        year = date2[0:4]\n",
    "        month = date2[5:7]\n",
    "        day = date2[8:10]\n",
    "\n",
    "        if len(str(month)) < 2:\n",
    "            month = str(0) + str(month)\n",
    "        else:\n",
    "            month = str(month)\n",
    "        if len(str(day)) < 2:\n",
    "            day = str(0) + str(day)\n",
    "        else:\n",
    "            day = str(day)\n",
    "\n",
    "        dirs = str(data_home) + '/' + str(data_type) + '/' + str(venue) + '/' + str(year) + '/' + str(\n",
    "                    month) + '/' + str(day) + '/'\n",
    "\n",
    "\n",
    "        if not (os.path.exists(dirs)):\n",
    "            continue\n",
    "        else:\n",
    "            print(year, month, day)\n",
    "            data = get_df(data_home, data_type, venue, year, month, day, ticker, bin_number, is_filter)\n",
    "            frames = [data_concat, data]\n",
    "            data_concat = pd.concat(frames)  # 将一只股票多天的数据合并到一个数据框里\n",
    "    data_concat = data_concat.reset_index(drop=True)  # 返回合并后的数据框并重新设置下标\n",
    "\n",
    "    def cal_volatility_1(a, b):\n",
    "        return (np.log(np.multiply(a,1/b)))**2\n",
    "    data_concat['part_volatility'] = cal_volatility_1(data_concat['max'], data_concat['min'])\n",
    "    data_concat['part_volatility'] = data_concat['part_volatility'].fillna(method = 'bfill')  # 空值用向上填充\n",
    "    def cal_volatility(df,j):\n",
    "        df['volatility'] = np.nan\n",
    "        for i in range(j,len(df['bin_num'])):\n",
    "            volatility = np.sqrt(sum(df['part_volatility'][i-j:i])/(4*j*(np.log(2))))\n",
    "            df.loc[i, 'volatility'] = volatility\n",
    "        return df  \n",
    "    data_concat = cal_volatility(data_concat,4)\n",
    "\n",
    "\n",
    "    data_concat.drop(['part_volatility',  'max','min','first','last'], axis=1, inplace=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return data_concat.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0425b35c-c0bf-4aa8-99b2-354cf8b4247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_home = '/volume1/sinoalgo/data/sinoalgo/JQMarketData'\n",
    "data_types = ['STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK']\n",
    "venues = ['XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE']\n",
    "tickers = ['000725', '300015', '300185', '000002', '000807', '002340', '000001','300750','300059','000166','000009']\n",
    "start_date = \"2020-09-01\"\n",
    "end_date = \"2021-06-30\"\n",
    "bin_num = 25\n",
    "\n",
    "\n",
    "def data_generating_all(data_home, data_types, venues, tickers,start_date,end_date,bin_num, is_filter=1):\n",
    "    data_home = data_home\n",
    "    for i in range(len(data_types)):\n",
    "        data_type = data_types[i]\n",
    "        venue = venues[i]\n",
    "        ticker = tickers[i]\n",
    "        result_df = read_stock_data_all(data_home, data_type, venue, start_date, end_date, ticker, bin_num, is_filter=0)\n",
    "        \n",
    "        filename_basic = ticker + '_daily.csv'\n",
    "        result_df.to_csv(filename_basic, index=False)\n",
    "        \n",
    "        \n",
    "data_generating_all(data_home,data_types,venues,tickers,start_date,end_date,bin_num,is_filter=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
