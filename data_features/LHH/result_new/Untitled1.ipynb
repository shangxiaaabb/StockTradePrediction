{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d490304c-c3a7-4f93-a3db-d6548838499c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import numpy as np\n",
    "import datetime\n",
    "import dateutil.parser as parser\n",
    "import math\n",
    "def read_stock_data(data_home, data_type, venue, year, month, day, ticker, is_filter):\n",
    "    '''\n",
    "    从sever中读取一只股票一天的数据\n",
    "    data_home:数据所在folder\n",
    "    data_type:类型\n",
    "    venue:交易所\n",
    "    is_filter:是否进行filter操作\n",
    "    '''\n",
    "\n",
    "    path = str(data_home) + '/' + str(data_type) + '/' + str(venue) + '/' + str(year) + '/' + str(\n",
    "        month) + '/' + str(day) + '/' + str(ticker) + '.' + str(venue)  # 读数据的路径\n",
    "\n",
    "    if (os.path.exists(path)):\n",
    "        data0 = open(path, 'r')\n",
    "        data1 = pd.read_csv(StringIO(data0.read()))\n",
    "        data = data1.loc[:, ['time', 'volume', 'current','a1_v','a1_p','b1_v','b1_p',]]\n",
    "        diff_df = data.loc[:, ['time', 'volume']].diff()  # 差分，求出每次交易的交易量、交易额\n",
    "        data.iloc[1:len(data['volume']), 1] = diff_df.iloc[1:len(data['volume']), 1] # 第0个为NaN,从第一个代替原数据的volume\n",
    "        data['current'] = data['current']/10000\n",
    "        data['spread'] = (data['a1_p'] - data['b1_p'])/(data['a1_p'] + data['b1_p'])  # 计算 spread\n",
    "        data['quote_imbalance'] = (data['b1_v'] - data['a1_v']) / (data['b1_v'] + data['a1_v'])\n",
    "        if is_filter == 0:  # 不filter数据的时候\n",
    "            return data\n",
    "        else:\n",
    "            quantile = np.percentile(data['volume'], 99.5)\n",
    "            quantile2 = np.percentile(data['volume'], 0.5) \n",
    "            data = data[(quantile2 <= data['volume']) & (data['volume'] <= quantile)]  \n",
    "            return data\n",
    "    else:\n",
    "        path = str(data_home) + '/' + str(data_type) + '/' + str(venue) + '/' + str(year) + '/' + str(\n",
    "            month) + '/' + str(day) + '/' + str(ticker) + '.' + str(venue) + '.gz'\n",
    "        with gzip.open(path, 'rb') as gf:\n",
    "            data1 = pd.read_csv(gf)\n",
    "        data = data1.loc[:, ['time', 'volume','current', 'a1_v','a1_p','b1_v','b1_p',]]\n",
    "        data['current'] = data['current']/10000\n",
    "        diff_df = data.loc[:, ['time', 'volume']].diff()  # 差分，求出每次交易的交易量、交易额\n",
    "        data.iloc[1:len(data['volume']), 1] = diff_df.iloc[1:len(data['volume']), 1] # 第0个为NaN,从第一个代替原数据的volume\n",
    "        data['quote_imbalance'] = (data['b1_v'] - data['a1_v']) / (data['b1_v'] + data['a1_v'])\n",
    "        if is_filter == 0:  # 不filter数据的时候\n",
    "            return data\n",
    "        else:\n",
    "            quantile = np.percentile(data['volume'], 99.5)\n",
    "            quantile2 = np.percentile(data['volume'], 0.5) \n",
    "            data = data[(quantile2 <= data['volume']) & (data['volume'] <= quantile)]  \n",
    "            return data\n",
    "def trans_date(date): \n",
    "    dates = []\n",
    "    for i in range(len(date)):\n",
    "        year = str(date[i])[0:4]\n",
    "        month = str(date[i])[4:6]\n",
    "        day = str(date[i])[6:8]\n",
    "        date_std = datetime.date(int(year), int(month), int(day)).isoformat()\n",
    "        dates.append(date_std)\n",
    "    return dates\n",
    "\n",
    "\n",
    "def trans_time(time):  \n",
    "    times = []\n",
    "    for i in range(len(time)):\n",
    "        hour = str(time[i])[8:10]\n",
    "        minute = str(time[i])[10:12]\n",
    "        second = str(time[i])[12:14]\n",
    "        time_std = datetime.time(int(hour), int(minute), int(second)).isoformat()\n",
    "        times.append(time_std)\n",
    "    return times\n",
    "\n",
    "\n",
    "\n",
    "def divide_bin(time, binnumber):  # 计算每条交易所属的bin number\n",
    "    '''\n",
    "    time:columns of time\n",
    "    '''\n",
    "    n = 237 / (binnumber - 1) * 60\n",
    "    bin_nums = []\n",
    "    for i in range(len(time)):\n",
    "        if datetime.datetime.strptime(time[i],\"%H:%M:%S\") < datetime.datetime.strptime(\"09:30:00\",\"%H:%M:%S\"):\n",
    "            bin_num = 0  # 交易发生在9：30之前，bin number为0\n",
    "        elif datetime.datetime.strptime(time[i],\"%H:%M:%S\")>datetime.datetime.strptime(\"15:00:00\",\"%H:%M:%S\"):\n",
    "            bin_num = binnumber+1\n",
    "        else:\n",
    "            starttime = parser.parse(datetime.time(9, 30, 0).isoformat())  # 开始时间设为9：30\n",
    "            endtime = parser.parse(time[i])  # 结束时间是该条数据的交易时间\n",
    "            s = (endtime - starttime).seconds  # 从开盘到现在的秒数\n",
    "            if s > -1 and s < 7201:  # 交易发生在9：30-11：30之前\n",
    "                bin_num = int((s - 0.5) // n) + 1  # 9：30之后的bin number从1开始\n",
    "            elif s > 12599 and s < 19801:  # 13:00-15:00\n",
    "                bin_num = int((s - 0.5 - 5400) // n)+1  # 去掉中间的90分钟\n",
    "            else:\n",
    "                bin_num = binnumber\n",
    "        bin_nums.append(bin_num)\n",
    "    return bin_nums\n",
    "\n",
    "    \n",
    "####### imbalance\n",
    "def cal_bin_volume(subdf, binnumber):\n",
    "    '''\n",
    "    subdf: data to be processed, DataFrame\n",
    "    return: DataFrame including one stock, ranked by bin number\n",
    "    '''\n",
    "\n",
    "    subdf = subdf[~subdf['bin_num'].isin([binnumber + 1])]  # Exclude rows with bin number binnumber+1\n",
    "    subdf = subdf[~subdf['bin_num'].isin([binnumber])]  # Exclude rows with bin number binnumber\n",
    "    subdf['current'].replace(0, float(\"NaN\"),inplace=True)\n",
    "    grouped = subdf.groupby(['date','bin_num'])\n",
    "    aggregated = grouped['current'].agg(['max', 'min', 'first', 'last']).reset_index()\n",
    "    \n",
    "    daily_volume = subdf['volume'].groupby(subdf['date']).sum().reset_index()  # Calculate total volume for each day\n",
    "    bin_volume = subdf['volume'].groupby([subdf['date'], subdf['bin_num']]).sum().reset_index()  # Calculate volume for each bin\n",
    "\n",
    "    df = pd.merge(daily_volume, bin_volume,how='outer', on='date')  # Merge daily_volume and bin_volume\n",
    "    \n",
    "    subdf1 = pd.merge(df, aggregated[['date', 'bin_num', 'max','min','first','last']], how='outer', on=['date','bin_num'])\n",
    "\n",
    "    \n",
    "    def exponential_weighted_average(numbers, alpha):\n",
    "        n = len(numbers)\n",
    "        weights = np.array([alpha ** (n - 1 - i) for i in range(n)])  # 使用倒序的权重计算\n",
    "        weighted_sum = np.sum(np.multiply(numbers, weights))\n",
    "        weight_sum = np.sum(weights)\n",
    "        ewma = weighted_sum / weight_sum\n",
    "        return ewma\n",
    "\n",
    "    imbalance = subdf['quote_imbalance'].groupby([subdf['date'], subdf['bin_num']]).apply(lambda x: exponential_weighted_average(x, 0.9)).reset_index()\n",
    "    subdf1 = pd.merge(subdf1,imbalance,how='outer',on=['date','bin_num'])\n",
    "    return subdf1\n",
    "\n",
    "\n",
    "def get_df(data_home, data_type, venue, year, month, day,ticker, bin_num, is_filter=0):\n",
    "    stock_data = read_stock_data(data_home, data_type, venue, year, month, day, ticker, is_filter=0)\n",
    "    stock_data = stock_data.reset_index(drop=True)\n",
    "    transdate = trans_date(stock_data['time'])\n",
    "    transtime = trans_time(stock_data['time'])\n",
    "    stock_data.loc[:, 'date'] = transdate  \n",
    "    stock_data.loc[:, 'timet'] = transtime\n",
    "    bin_nums = divide_bin(time=stock_data['timet'], binnumber=bin_num)\n",
    "    stock_data.loc[:, 'bin_num'] = bin_nums\n",
    "    vol_df = cal_bin_volume(subdf=stock_data, binnumber=bin_num)\n",
    "    vol_df = vol_df.rename(columns={'volume_x': 'daily_volume'})\n",
    "    vol_df = vol_df.rename(columns={'volume_y': 'bin_volume'})\n",
    "    vol_df['bin_volume'] = vol_df['bin_volume'].fillna(1)  # 空值用1填充\n",
    "    vol_df['daily_volume'] = vol_df['daily_volume'].fillna(method = 'bfill')  # 空值用向上填充\n",
    "    return vol_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c226353b-5961-47d1-aa49-4eaaeb42bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_stock_data_all(data_home, data_type, venue, start_date, end_date, ticker, bin_number, is_filter):\n",
    "    '''\n",
    "    读取一只股票所有日期的数据，from start_date to end_date\n",
    "    '''\n",
    "\n",
    "    data_concat = pd.DataFrame(columns=['date', 'daily_volume', 'bin_num', 'bin_volume'])\n",
    "\n",
    "    start_date1 = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date1 = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
    "    interval_day = (end_date1-start_date1).days\n",
    "\n",
    "    ##遍历日期\n",
    "\n",
    "    for i in range(interval_day+1):\n",
    "        date = datetime.datetime.strptime(start_date,'%Y-%m-%d') + datetime.timedelta(days=i)\n",
    "\n",
    "        date2 = datetime.datetime.strftime(date, '%Y-%m-%d')\n",
    "        year = date2[0:4]\n",
    "        month = date2[5:7]\n",
    "        day = date2[8:10]\n",
    "\n",
    "        if len(str(month)) < 2:\n",
    "            month = str(0) + str(month)\n",
    "        else:\n",
    "            month = str(month)\n",
    "        if len(str(day)) < 2:\n",
    "            day = str(0) + str(day)\n",
    "        else:\n",
    "            day = str(day)\n",
    "\n",
    "        dirs = str(data_home) + '/' + str(data_type) + '/' + str(venue) + '/' + str(year) + '/' + str(\n",
    "                    month) + '/' + str(day) + '/'\n",
    "\n",
    "\n",
    "        if not (os.path.exists(dirs)):\n",
    "            continue\n",
    "        else:\n",
    "            print(year, month, day)\n",
    "            data = get_df(data_home, data_type, venue, year, month, day, ticker, bin_number, is_filter)\n",
    "            frames = [data_concat, data]\n",
    "            data_concat = pd.concat(frames)  # 将一只股票多天的数据合并到一个数据框里\n",
    "\n",
    "    data_concat.reset_index(drop=True)  # 返回合并后的数据框并重新设置下标\n",
    "\n",
    "    def cal_volatility_1(a, b):\n",
    "        return (np.log(np.multiply(a,1/b)))**2\n",
    "\n",
    "\n",
    "    def cal_volatility_2(df):\n",
    "        return (2 * (np.log(2)) - 1) * (np.log(np.multiply(df['last'], 1 / df['last'].shift(1)))).astype(float) ** 2\n",
    "    \n",
    "\n",
    "    df.reset_index(drop=True)\n",
    "     bin_volatility_part1 = data_concat.apply(lambda x: cal_volatility_1(x['max'], x['min']), axis=1)\n",
    "    data_concat['bin_volatility_part2'] = cal_volatility_2(x['last'])\n",
    "\n",
    "    def cal_volatility(df,j):\n",
    "        df['volatility'] = np.nan\n",
    "        for i in range(j,len(df['bin_num'])):\n",
    "            volatility = np.sqrt(sum(df['bin_volatility_part1'][i-j:i])/(2*j)-sum(df['bin_volatility_part2'][i-j:i])/j)\n",
    "            df.loc[i, 'volatility'] = volatility\n",
    "        return df  \n",
    "    data_concat['bin_volatility_part1'] = data_concat.apply(lambda x: cal_volatility_1(x['max'], x['min']), axis=1)\n",
    "    data_concat['bin_volatility_part2'] = cal_volatility_2(data_concat)\n",
    "\n",
    "        \n",
    "    return data_concat  # 返回合并后的数据框并重新设置下标\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0d8610ad-b63c-4cdd-9b16-6f4704217569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 09 01\n",
      "2020 09 02\n",
      "2020 09 03\n",
      "2020 09 04\n",
      "2020 09 07\n",
      "2020 09 08\n",
      "2020 09 09\n",
      "2020 09 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2199565/2984795327.py\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mresult_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_with_volatility\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mdata_generating_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvenues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbin_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2199565/2984795327.py\u001b[0m in \u001b[0;36mdata_generating_all\u001b[0;34m(data_home, data_types, venues, tickers, start_date, end_date, bin_num, is_filter)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvenue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvenues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mticker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtickers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_stock_data_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvenue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mfilename_basic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'123'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_daily.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2199565/1356699050.py\u001b[0m in \u001b[0;36mread_stock_data_all\u001b[0;34m(data_home, data_type, venue, start_date, end_date, ticker, bin_number, is_filter)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcal_volatility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'volatility'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "data_home = '/volume1/sinoalgo/data/sinoalgo/JQMarketData'\n",
    "data_types = ['STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK', 'STOCK']\n",
    "venues = ['XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE', 'XSHE']\n",
    "tickers = ['000725', '300015', '300185', '000002', '000807', '002340', '000001','300750','300059','000166','000009']\n",
    "start_date = \"2020-09-01\"\n",
    "end_date = \"2020-09-10\"\n",
    "bin_num = 25\n",
    "\n",
    "\n",
    "def data_generating_all(data_home, data_types, venues, tickers,start_date,end_date,bin_num, is_filter=1):\n",
    "    data_home = data_home\n",
    "    for i in range(len(data_types)):\n",
    "        data_type = data_types[i]\n",
    "        venue = venues[i]\n",
    "        ticker = tickers[i]\n",
    "        result_df = read_stock_data_all(data_home, data_type, venue, start_date, end_date, ticker, bin_num, is_filter=0)\n",
    "        \n",
    "        filename_basic = '123' + '_daily.csv'\n",
    "        result_df.to_csv(filename_basic, index=False)\n",
    "        \n",
    "         # 输出包含'volatility'列的结果\n",
    "        filename_with_volatility = '123' + '_daily_with_volatility.csv'\n",
    "        result_df = cal_volatility(result_df, 4)  # 假设窗口大小为4\n",
    "        result_df.to_csv(filename_with_volatility, index=False)\n",
    "        \n",
    "data_generating_all(data_home,data_types,venues,tickers,start_date,end_date,bin_num,is_filter=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a8a55c-a9c0-4754-a004-c62f2e7eb6de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
