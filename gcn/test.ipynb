{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from data_loader import StockDataset\n",
    "from model.GHATModel import GAT\n",
    "from config import Config\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def build_adj():\n",
    "    # connection = [\n",
    "    # (1, 0),\n",
    "    # (9, 0), (12, 0), \n",
    "    # (8, 9), (8, 12), (5, 9), (11, 12), \n",
    "    # (4, 5), (4, 8), (7, 8), (7, 11), (10, 11),\n",
    "    # (3, 4), (3, 7), (6, 7), (6, 10), (2, 3), (2, 6)]\n",
    "    \n",
    "    # 无向图\n",
    "    connection = [\n",
    "        (1, 0), (0, 1),\n",
    "        (9, 0), (12, 0), (0, 9), (0, 12),\n",
    "        (8, 9), (8, 12), (5, 9), (11, 12), (9, 8), (12, 8), (9, 5), (12, 11),\n",
    "        (4, 5), (4, 8), (7, 8), (7, 11), (10, 11), (5, 4), (8, 4), (8, 7), (11, 7), (11, 10),\n",
    "        (3, 4), (3, 7), (6, 7), (6, 10), (2, 3), (2, 6), (4, 3), (7, 3), (7, 6), (10, 6), (3, 2), (6, 2)\n",
    "        ]\n",
    "    adj_matrix = torch.zeros(13, 13).float()\n",
    "    for source, target in connection:\n",
    "        adj_matrix[source][target] = 1\n",
    "    return adj_matrix\n",
    "\n",
    "large_market_cap_stocks = [\n",
    "    \"000951\", \"002841\", \"300133\", \"300343\", \"000998\", \"300433\",\n",
    "    \"601021\", \"603197\", \"300166\", \"600026\", \"000998\", \"600171\",\n",
    "    \"300917\", \"603087\", \"002309\", \"300451\", \"002549\", \"603466\"\n",
    "]\n",
    "\n",
    "medium_market_cap_stocks = [\n",
    "    \"300540\", \"603359\", \"000046\", \"300263\", \"002679\", \"603053\",\n",
    "    \"000403\", \"603306\", \"600970\", \"002703\", \"000931\", \"002186\",\n",
    "    \"300633\", \"603195\", \"300133\", \"600360\", \"600729\", \"603777\"\n",
    "]\n",
    "\n",
    "small_market_cap_stocks = [\n",
    "    \"300174\", \"603095\", \"000753\", \"600622\", \"002282\", \"002882\",\n",
    "    \"300912\", \"603926\", \"002451\", \"002672\", \"000551\", \"300758\",\n",
    "    \"001207\", \"300865\", \"002247\", \"002379\", \"300389\", \"300491\"\n",
    "]\n",
    "market_cap = {'large': large_market_cap_stocks, 'medium': medium_market_cap_stocks, 'small': small_market_cap_stocks}\n",
    "\n",
    "# 高流动股票代码列表（前六位）\n",
    "high_flow_stocks = [\n",
    "    \"300133\", \"300343\", \"000046\", \"300263\", \"000753\", \"600622\", \n",
    "    \"300166\", \"600026\", \"600970\", \"002703\", \"002451\", \"002672\", \n",
    "    \"002309\", \"300451\", \"300133\", \"600360\", \"002247\", \"002379\"\n",
    "]\n",
    "\n",
    "# 中流动股票代码列表（前六位）\n",
    "medium_flow_stocks = [\n",
    "    \"000998\", \"300433\", \"002679\", \"603053\", \"002282\", \"002882\", \n",
    "    \"000998\", \"600171\", \"000931\", \"002186\", \"000551\", \"300758\", \n",
    "    \"002549\", \"603466\", \"600729\", \"603777\", \"300389\", \"300491\"\n",
    "]\n",
    "\n",
    "# 低流动股票代码列表（前六位）\n",
    "low_flow_stocks = [\n",
    "    \"000951\", \"002841\", \"300540\", \"603359\", \"300174\", \"603095\", \n",
    "    \"601021\", \"603197\", \"000403\", \"603306\", \"300912\", \"603926\", \n",
    "    \"300917\", \"603087\", \"300633\", \"603195\", \"001207\", \"300865\"\n",
    "]\n",
    "flow_dict = {'high': high_flow_stocks, 'medium': medium_flow_stocks, 'low': low_flow_stocks}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_pred_300263.csv com is 0.935416413980514\n",
      "model_pred_002882.csv com is 1.550863929888626\n",
      "model_pred_002841.csv com is -1.0267474556341747\n",
      "model_pred_002282.csv com is 3.756918435396213\n",
      "model_pred_300174.csv com is -0.4021384301654137\n",
      "model_pred_000998.csv com is -0.12983024485678749\n",
      "model_pred_000951.csv com is -1.3434334328673543\n",
      "model_pred_000046.csv com is -0.46476788085150367\n",
      "model_pred_300133.csv com is 0.8758025108458504\n",
      "model_pred_000753.csv com is 1.9249466546347918\n"
     ]
    }
   ],
   "source": [
    "pred_dir = './pred/'\n",
    "scaler_dir = './data/volume/0308/Scaler/'\n",
    "\n",
    "for path in os.listdir(pred_dir):\n",
    "    if path.endswith('.csv'):\n",
    "        date_suffix = path[-10:-4]\n",
    "        scaler_path = os.path.join(scaler_dir, f'{date_suffix}.m')\n",
    "        \n",
    "        stand = joblib.load(scaler_path)\n",
    "        data = pd.read_csv(os.path.join(pred_dir, path))\n",
    "        \n",
    "        data.iloc[:, 0] = stand.transform(data.iloc[:, 0].values.reshape(-1, 1)).flatten().astype(float)\n",
    "        data.iloc[:, 1] = stand.transform(data.iloc[:, 1].values.reshape(-1, 1)).flatten().astype(float)\n",
    "        \n",
    "        aps_value = np.abs(data.iloc[:, 0] - data.iloc[:, 1])\n",
    "        mape = np.mean(aps_value/data.iloc[:, 1])\n",
    "        # mean_difference = np.mean(np.abs(data.iloc[:, 0] - data.iloc[:, 1])/data.iloc[:, 1])\n",
    "        print(f\"{path} com is {mape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Tensorboard\n",
    "\n",
    "save_models/saved_models-64-0.2-MSELoss/000951/scalar 558.3517 0.0579\n",
    "\n",
    "save_models/saved_models-128-0.1-L1Loss/002882/scalar 0.6444 0.111  \n",
    "\n",
    "save_models/saved_models-32-0.1-L1Loss/000951/scalar  0.3645  0.1776\n",
    "\n",
    "save_models/saved_models-128-0.3-L1Loss/300263/scalar 5.4386  0.2057\n",
    "\n",
    "save_models/saved_models-32-0.1-L1Loss/300174/scalar  0.6048  0.2104  \n",
    "\n",
    "save_models/saved_models-128-0.1-L1Loss/000046/scalar  0.3891  0.215\n",
    "\n",
    "save_models/saved_models-32-0.1-L1Loss/300133/scalar 0.4245 0.2317\n",
    "\n",
    "save_models/saved_models-128-0.1-L1Loss/000753/scalar  1.1202  0.2362\n",
    "\n",
    "save_models/saved_models-32-0.1-L1Loss/000753/scalar  0.6045 0.2512\n",
    "\n",
    "save_models/saved_models-128-0.1-L1Loss/002841/scalar  0.4857  0.461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000951 com MAE is 0.17173053386621098, the MAPE is 2.518633466308861, the MSE is 0.5221717812411385\n",
      "002882 com MAE is 0.12423068589359212, the MAPE is 2.1046718006878993, the MSE is 0.26982633313342996\n",
      "300263 com MAE is 0.3505307760632711, the MAPE is 3.1935994183582874, the MSE is 0.6466603122536327\n",
      "300174 com MAE is 0.2546607789525313, the MAPE is 2.1168768878390187, the MSE is 0.7743779097974093\n",
      "000046 com MAE is 0.14571692178444937, the MAPE is 2.8024512486183615, the MSE is 0.46706784226470577\n",
      "300133 com MAE is 0.4677060045788819, the MAPE is 6.006919753169601, the MSE is 0.8068875438268603\n",
      "000753 com MAE is 0.3408899679655601, the MAPE is 4.5000158535369925, the MSE is 0.997200295958236\n",
      "002841 com MAE is 0.3678779471036437, the MAPE is 4.670743773679899, the MSE is 0.7112576372651055\n",
      "000998 com MAE is 0.11683616764812571, the MAPE is 2.3214763711409097, the MSE is 0.39026816087632676\n"
     ]
    }
   ],
   "source": [
    "model_path = pd.read_excel('./model.xlsx')\n",
    "path_dict = {}\n",
    "for path in model_path['path']:\n",
    "    for _ in os.listdir(path.split('/scalar')[0]):\n",
    "        if 'train' in _ and '.tar' not in _:\n",
    "            pt_path = os.path.join(path, _).replace('/scalar', '')\n",
    "            pt_path = f\"./{pt_path}\"\n",
    "            pred_path = f'./pred/model_pred_{_[:6]}.csv'\n",
    "            data_path = f'./data/volume/0308/Input/{_[:6]}_3_3_inputs.npy'\n",
    "            path_dict[_[:6]] = [pt_path, data_path, pred_path]\n",
    "\n",
    "for key, value in path_dict.items():\n",
    "    pt_path, data_path, pred_path = value[0], value[1], value[2]\n",
    "    \n",
    "    # load data\n",
    "    data = np.load(data_path, allow_pickle= True)\n",
    "    data = np.array([value[_] for item in data for value in item for _ in [0, 1, 2, 3, 4, 5, 6, 7, 8]], dtype= np.float32).reshape(data.shape[0], 13, 9)\n",
    "    data = torch.from_numpy(data).to(device)\n",
    "\n",
    "    # load model\n",
    "    model = GAT(n_feat= len([0, 1, 2, 3, 4, 5, 6, 7, 8]), n_hid= 16, out_features= len([1]), \n",
    "                pred_length= 1, n_heads= 4)\n",
    "    model = model.to(device= device)\n",
    "\n",
    "    state_dict = torch.load(pt_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # model pred\n",
    "    model_pred = model(data, build_adj())\n",
    "    model_pred = model_pred.cpu().detach().numpy()\n",
    "\n",
    "    # to csv\n",
    "    pred_data = pd.read_csv(pred_path)\n",
    "    pred_data[f'{key}-pred'] = model_pred\n",
    "    pred_data.to_csv(f'./result/{key}.csv', index= None)\n",
    "\n",
    "    # com model performance\n",
    "    non_zero_mask = pred_data[f'{key}-true'] != 0\n",
    "    mape = np.mean(np.abs((pred_data[f'{key}-true'][non_zero_mask]- pred_data[f'{key}-pred'][non_zero_mask])/ pred_data[f'{key}-true'][non_zero_mask]))\n",
    "    # mape = np.mean(np.abs((pred_data[f'{key}-true']- pred_data[f'{key}-pred'])/ (pred_data[f'{key}-true']+ 1e-8)))\n",
    "    mae = np.mean(pred_data[f'{key}-true']- pred_data[f'{key}-pred'])\n",
    "    mse = np.mean((pred_data[f'{key}-true']- pred_data[f'{key}-pred'])** 2)\n",
    "\n",
    "    print(f\"{key} com MAE is {mae}, the MAPE is {mape}, the MSE is {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| stock |  MAE   | MAPE | MSE  |\n",
    "| :--:  | :--:   | :--: | :--: |\n",
    "| 000046 | 0.067 | 2.784| 0.444|\n",
    "| 002882 | 0.094 | 4.669| 0.710|\n",
    "| 000951 | 0.194 | 2.633| 0.568|\n",
    "| 300263 | 0.330 | 2.967| 0.609|\n",
    "| 300174 | 0.229 | 2.031| 0.746|\n",
    "| 300133 | 0.430 | 5.966| 0.785|\n",
    "| 000753 | 0.357 | 4.565| 1.047|\n",
    "| 002841 | 0.369 | 4.688| 0.713|\n",
    "| 000998 | 0.091 | 2.411| 0.367|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000753 com MAE is 0.3568296744179487, the MAPE is 4.565257975045892, the MSE is 1.0468893311222307\n",
      "300263 com MAE is 0.3301482182794872, the MAPE is 2.966666300469162, the MSE is 0.6086557043995929\n",
      "000998 com MAE is 0.0915205719877487, the MAPE is 2.4114674667919633, the MSE is 0.36674533100505274\n",
      "000951 com MAE is 0.19498004116868423, the MAPE is 2.6327771803610047, the MSE is 0.5684222432400793\n",
      "300133 com MAE is 0.4397617898415026, the MAPE is 5.966244515032575, the MSE is 0.7851925197273011\n",
      "000046 com MAE is 0.06712500368747397, the MAPE is 2.7842108061709787, the MSE is 0.4440601307134777\n",
      "002882 com MAE is 0.09368558017979427, the MAPE is 2.097611695986554, the MSE is 0.3116063670139982\n",
      "002841 com MAE is 0.3670204628341969, the MAPE is 4.669078104983375, the MSE is 0.7103900892096832\n",
      "300174 com MAE is 0.22933013198451282, the MAPE is 2.030887703447141, the MSE is 0.7463646253501821\n"
     ]
    }
   ],
   "source": [
    "result = './end_result/'\n",
    "for data_path in os.listdir(result):\n",
    "    pred_data = pd.read_csv(f'{result}{data_path}')\n",
    "    key = data_path.split('.csv')[0]\n",
    "    # com model performance\n",
    "    non_zero_mask = pred_data[f'{key}-true'] != 0\n",
    "    mape = np.mean(np.abs((pred_data[f'{key}-true'][non_zero_mask]- pred_data[f'{key}-pred'][non_zero_mask])/ (pred_data[f'{key}-true'][non_zero_mask])))\n",
    "    mae = np.mean(pred_data[f'{key}-true']- pred_data[f'{key}-pred'])\n",
    "    mse = np.mean((pred_data[f'{key}-true']- pred_data[f'{key}-pred'])** 2)\n",
    "\n",
    "    print(f\"{key} com MAE is {mae}, the MAPE is {mape}, the MSE is {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300433_XSHE_25_daily.csv the corr is -0.05018412780538093\n",
      "000951_XSHE_25_daily.csv the corr is 0.006499070456356722\n",
      "000046_XSHE_25_daily.csv the corr is -0.025292199108096332\n",
      "000998_XSHE_25_daily.csv the corr is -0.06417301369701807\n",
      "002679_XSHE_25_daily.csv the corr is -0.04395794009055617\n",
      "300263_XSHE_25_daily.csv the corr is -0.044277313292397036\n",
      "300540_XSHE_25_daily.csv the corr is 0.01619292344657734\n",
      "603053_XSHG_25_daily.csv the corr is -0.03826706361246143\n",
      "600622_XSHG_25_daily.csv the corr is -0.02819947489846059\n",
      "300174_XSHE_25_daily.csv the corr is -0.03089981921673612\n",
      "002882_XSHE_25_daily.csv the corr is -0.024562945968328902\n",
      "000753_XSHE_25_daily.csv the corr is -0.012347011070974035\n",
      "603359_XSHG_25_daily.csv the corr is -0.007381870227684722\n",
      "300133_XSHE_25_daily.csv the corr is -0.023778421675317782\n",
      "002282_XSHE_25_daily.csv the corr is -0.015833455705401456\n",
      "002841_XSHE_25_daily.csv the corr is -0.02189742569235223\n",
      "300343_XSHE_25_daily.csv the corr is -0.026467016324222114\n",
      "603095_XSHG_25_daily.csv the corr is -0.01751676568552221\n"
     ]
    }
   ],
   "source": [
    "path_dir = './data/0308/0308-data/'\n",
    "path_list = os.listdir(path_dir)\n",
    "for path in path_list:\n",
    "    test = pd.read_csv(f'{path_dir}{path}')\n",
    "    corr_value = test.iloc[:, 1:].corr()\n",
    "    print(f'{path} the corr is {corr_value.iloc[0, 4]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_low = pd.read_csv('./data/0308/0308-data/000046_XSHE_25_daily.csv')\n",
    "data_medium = pd.read_csv('./data/0308/0308-data/002882_XSHE_25_daily.csv')\n",
    "data_heigh = pd.read_csv('./data/0308/0308-data/000998_XSHE_25_daily.csv')\n",
    "data_analysis = {'low': data_low, 'medium': data_medium, 'heigh': data_heigh}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bbox(data_dict: dict):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=len(data_dict), figsize=(12, 5))\n",
    "    for i, (key, value) in enumerate(data_dict.items()):\n",
    "        sns.boxplot(value['daily_volume'], ax= axes[i])\n",
    "        axes[i].set_xlabel(f'{key}')\n",
    "        axes[i].set_ylabel('daily_volume')\n",
    "    # 调整子图之间的间距\n",
    "    plt.tight_layout()\n",
    "    # 显示图表\n",
    "    plt.show()\n",
    "\n",
    "def com_return(path_dir: str):\n",
    "    path_list = os.listdir(path_dir)\n",
    "    with tqdm(total=len(path_list)) as pbar:\n",
    "        for path in path_list:\n",
    "            file_path = os.path.join(path_dir, path)\n",
    "            data = pd.read_excel(file_path)\n",
    "            # data['收益率'] = data['收盘点位'].pct_change()\n",
    "            data['日收益率'] = (data['收盘价'] - data['昨收价']) / data['昨收价'] * 100\n",
    "            data = data.dropna()\n",
    "\n",
    "            data.to_excel(f\"./StockData/{path.split('.')[0]}.xlsx\")\n",
    "            pbar.update(1)\n",
    "\n",
    "def com_stock_return(file_path_target: str, file_path_all: str):\n",
    "    market_dict = {}\n",
    "    for root, dirs, files in os.walk(file_path_target):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv'):\n",
    "                target_path = os.path.join(root, file)\n",
    "                test1 = pd.read_csv(target_path)\n",
    "                end, start = str(test1['time'].max())[:8], str(test1['time'].min())[:8]\n",
    "                end, start = int(end), int(start)\n",
    "\n",
    "                stock_info = target_path.split('_')[1][-6:]\n",
    "\n",
    "                # get com return data path\n",
    "                if os.path.exists(os.path.join(file_path_all, f\"{stock_info}.SZ.xls\")):\n",
    "                    path_used = os.path.join(file_path_all, f\"{stock_info}.SZ.xls\")\n",
    "                else:\n",
    "                    path_used = os.path.join(file_path_all, f\"{stock_info}.SH.xls\")\n",
    "\n",
    "                # open file\n",
    "                try:\n",
    "                    df = pd.read_excel(path_used)\n",
    "\n",
    "                    # com daily_return and yead_return\n",
    "                    daily_return = (df['收盘价'] - df['昨收价']) / df['昨收价'] * 100\n",
    "                    year_return = daily_return.std()* np.sqrt(252)\n",
    "                    # print(f\"The {stock_info} Annualized Volatility {year_return}\")\n",
    "                    market_dict[stock_info] = year_return\n",
    "                except Exception:\n",
    "                    continue\n",
    "    return market_dict\n",
    "\n",
    "# plot_bbox(data_dict= data_analysis)\n",
    "# com_return(path_dir= './stockData/allstock/')\n",
    "\n",
    "\n",
    "market_return = com_stock_return(file_path_target= './data/raw_data/', file_path_all= './stockData/allstock/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000403': 83.94171399855212,\n",
       " '600171': 49.431082769848935,\n",
       " '000551': 46.50375391336568,\n",
       " '002703': 246.06839649718341,\n",
       " '000998': 68.47825078391368,\n",
       " '002672': 41.42633479227145,\n",
       " '600026': 49.93037604196431,\n",
       " '000931': 711.7914954246801,\n",
       " '600970': 59.77701983835026,\n",
       " '603306': 49.6107296401739,\n",
       " '002186': 88.21341202517382,\n",
       " '300758': 66.66853128226039,\n",
       " '601021': 46.600327475973614,\n",
       " '300166': 58.26820108949775,\n",
       " '603197': 58.51819068581007,\n",
       " '603926': 48.08719028720553,\n",
       " '002451': 59.7939809524463,\n",
       " '300633': 58.063514324622176,\n",
       " '300389': 57.66784187527512,\n",
       " '600360': 64.38524516755488,\n",
       " '600729': 40.57379679498191,\n",
       " '603195': 87.85985838233813,\n",
       " '002247': 50.5248307861731,\n",
       " '002379': 50.15308049963824,\n",
       " '603466': 59.71602967430237,\n",
       " '300451': 68.05646239340707,\n",
       " '002309': 44.45894984085891,\n",
       " '300491': 66.12479336938773,\n",
       " '300133': 53.877745104515355,\n",
       " '603777': 59.42841792615807,\n",
       " '603087': 181.59597335111425,\n",
       " '002549': 50.55504593970418,\n",
       " '300433': 61.93785048792762,\n",
       " '000951': 51.66226411810109,\n",
       " '000046': 47.05557654752438,\n",
       " '002679': 57.31379553203301,\n",
       " '300263': 52.404450133453096,\n",
       " '300540': 60.176878569756205,\n",
       " '603053': 77.63344371829432,\n",
       " '600622': 48.38823727448727,\n",
       " '300174': 50.51133548968239,\n",
       " '002882': 50.581170107072545,\n",
       " '000753': 44.25366753338578,\n",
       " '603359': 48.63193625287926,\n",
       " '002282': 51.8801265961952,\n",
       " '002841': 49.23137771789938,\n",
       " '300343': 59.716901180533974,\n",
       " '603095': 97.87555783578242}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
