{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from data_loader import StockDataset\n",
    "from model.GHATModel import GAT\n",
    "from config import Config\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def build_adj():\n",
    "    # connection = [\n",
    "    # (1, 0),\n",
    "    # (9, 0), (12, 0), \n",
    "    # (8, 9), (8, 12), (5, 9), (11, 12), \n",
    "    # (4, 5), (4, 8), (7, 8), (7, 11), (10, 11),\n",
    "    # (3, 4), (3, 7), (6, 7), (6, 10), (2, 3), (2, 6)]\n",
    "    \n",
    "    # 无向图\n",
    "    connection = [\n",
    "        (1, 0), (0, 1),\n",
    "        (9, 0), (12, 0), (0, 9), (0, 12),\n",
    "        (8, 9), (8, 12), (5, 9), (11, 12), (9, 8), (12, 8), (9, 5), (12, 11),\n",
    "        (4, 5), (4, 8), (7, 8), (7, 11), (10, 11), (5, 4), (8, 4), (8, 7), (11, 7), (11, 10),\n",
    "        (3, 4), (3, 7), (6, 7), (6, 10), (2, 3), (2, 6), (4, 3), (7, 3), (7, 6), (10, 6), (3, 2), (6, 2)\n",
    "        ]\n",
    "    adj_matrix = torch.zeros(13, 13).float()\n",
    "    for source, target in connection:\n",
    "        adj_matrix[source][target] = 1\n",
    "    return adj_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_pred_300263.csv com is 0.935416413980514\n",
      "model_pred_002882.csv com is 1.550863929888626\n",
      "model_pred_002841.csv com is -1.0267474556341747\n",
      "model_pred_002282.csv com is 3.756918435396213\n",
      "model_pred_300174.csv com is -0.4021384301654137\n",
      "model_pred_000998.csv com is -0.12983024485678749\n",
      "model_pred_000951.csv com is -1.3434334328673543\n",
      "model_pred_000046.csv com is -0.46476788085150367\n",
      "model_pred_300133.csv com is 0.8758025108458504\n",
      "model_pred_000753.csv com is 1.9249466546347918\n"
     ]
    }
   ],
   "source": [
    "pred_dir = './pred/'\n",
    "scaler_dir = './data/volume/0308/Scaler/'\n",
    "\n",
    "for path in os.listdir(pred_dir):\n",
    "    if path.endswith('.csv'):\n",
    "        date_suffix = path[-10:-4]\n",
    "        scaler_path = os.path.join(scaler_dir, f'{date_suffix}.m')\n",
    "        \n",
    "        stand = joblib.load(scaler_path)\n",
    "        data = pd.read_csv(os.path.join(pred_dir, path))\n",
    "        \n",
    "        data.iloc[:, 0] = stand.transform(data.iloc[:, 0].values.reshape(-1, 1)).flatten().astype(float)\n",
    "        data.iloc[:, 1] = stand.transform(data.iloc[:, 1].values.reshape(-1, 1)).flatten().astype(float)\n",
    "        \n",
    "        aps_value = np.abs(data.iloc[:, 0] - data.iloc[:, 1])\n",
    "        mape = np.mean(aps_value/data.iloc[:, 1])\n",
    "        # mean_difference = np.mean(np.abs(data.iloc[:, 0] - data.iloc[:, 1])/data.iloc[:, 1])\n",
    "        print(f\"{path} com is {mape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save_models/saved_models-64-0.2-MSELoss/000951/scalar 558.3517 0.0579\n",
    "\n",
    "save_models/saved_models-128-0.1-L1Loss/002882/scalar 0.6444 0.111  \n",
    "\n",
    "save_models/saved_models-32-0.1-L1Loss/000951/scalar  0.3645  0.1776\n",
    "\n",
    "save_models/saved_models-128-0.3-L1Loss/300263/scalar 5.4386  0.2057\n",
    "\n",
    "save_models/saved_models-32-0.1-L1Loss/300174/scalar  0.6048  0.2104  \n",
    "\n",
    "save_models/saved_models-128-0.1-L1Loss/000046/scalar  0.3891  0.215\n",
    "\n",
    "save_models/saved_models-32-0.1-L1Loss/300133/scalar 0.4245 0.2317\n",
    "\n",
    "save_models/saved_models-128-0.1-L1Loss/000753/scalar  1.1202  0.2362\n",
    "\n",
    "save_models/saved_models-32-0.1-L1Loss/000753/scalar  0.6045 0.2512\n",
    "\n",
    "save_models/saved_models-128-0.1-L1Loss/002841/scalar  0.4857  0.461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000951 com MAE is 0.17173053386621098, the MAPE is 2.518633466308861, the MSE is 0.5221717812411385\n",
      "002882 com MAE is 0.12423068589359212, the MAPE is 2.1046718006878993, the MSE is 0.26982633313342996\n",
      "300263 com MAE is 0.3505307760632711, the MAPE is 3.1935994183582874, the MSE is 0.6466603122536327\n",
      "300174 com MAE is 0.2546607789525313, the MAPE is 2.1168768878390187, the MSE is 0.7743779097974093\n",
      "000046 com MAE is 0.14571692178444937, the MAPE is 2.8024512486183615, the MSE is 0.46706784226470577\n",
      "300133 com MAE is 0.4677060045788819, the MAPE is 6.006919753169601, the MSE is 0.8068875438268603\n",
      "000753 com MAE is 0.3408899679655601, the MAPE is 4.5000158535369925, the MSE is 0.997200295958236\n",
      "002841 com MAE is 0.3678779471036437, the MAPE is 4.670743773679899, the MSE is 0.7112576372651055\n",
      "000998 com MAE is 0.11683616764812571, the MAPE is 2.3214763711409097, the MSE is 0.39026816087632676\n"
     ]
    }
   ],
   "source": [
    "model_path = pd.read_excel('./model.xlsx')\n",
    "path_dict = {}\n",
    "for path in model_path['path']:\n",
    "    for _ in os.listdir(path.split('/scalar')[0]):\n",
    "        if 'train' in _ and '.tar' not in _:\n",
    "            pt_path = os.path.join(path, _).replace('/scalar', '')\n",
    "            pt_path = f\"./{pt_path}\"\n",
    "            pred_path = f'./pred/model_pred_{_[:6]}.csv'\n",
    "            data_path = f'./data/volume/0308/Input/{_[:6]}_3_3_inputs.npy'\n",
    "            path_dict[_[:6]] = [pt_path, data_path, pred_path]\n",
    "\n",
    "for key, value in path_dict.items():\n",
    "    pt_path, data_path, pred_path = value[0], value[1], value[2]\n",
    "    \n",
    "    # load data\n",
    "    data = np.load(data_path, allow_pickle= True)\n",
    "    data = np.array([value[_] for item in data for value in item for _ in [0, 1, 2, 3, 4, 5, 6, 7, 8]], dtype= np.float32).reshape(data.shape[0], 13, 9)\n",
    "    data = torch.from_numpy(data).to(device)\n",
    "\n",
    "    # load model\n",
    "    model = GAT(n_feat= len([0, 1, 2, 3, 4, 5, 6, 7, 8]), n_hid= 16, out_features= len([1]), \n",
    "                pred_length= 1, n_heads= 4)\n",
    "    model = model.to(device= device)\n",
    "\n",
    "    state_dict = torch.load(pt_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    # model pred\n",
    "    model_pred = model(data, build_adj())\n",
    "    model_pred = model_pred.cpu().detach().numpy()\n",
    "\n",
    "    # to csv\n",
    "    pred_data = pd.read_csv(pred_path)\n",
    "    pred_data[f'{key}-pred'] = model_pred\n",
    "    pred_data.to_csv(f'./result/{key}.csv', index= None)\n",
    "\n",
    "    # com model performance\n",
    "    non_zero_mask = pred_data[f'{key}-true'] != 0\n",
    "    mape = np.mean(np.abs((pred_data[f'{key}-true'][non_zero_mask]- pred_data[f'{key}-pred'][non_zero_mask])/ pred_data[f'{key}-true'][non_zero_mask]))\n",
    "    # mape = np.mean(np.abs((pred_data[f'{key}-true']- pred_data[f'{key}-pred'])/ (pred_data[f'{key}-true']+ 1e-8)))\n",
    "    mae = np.mean(pred_data[f'{key}-true']- pred_data[f'{key}-pred'])\n",
    "    mse = np.mean((pred_data[f'{key}-true']- pred_data[f'{key}-pred'])** 2)\n",
    "\n",
    "    print(f\"{key} com MAE is {mae}, the MAPE is {mape}, the MSE is {mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| stock |  MAE   | MAPE | MSE  |\n",
    "| :--:  | :--:   | :--: | :--: |\n",
    "| 000046 | 0.067 | 2.784| 0.444|\n",
    "| 002882 | 0.094 | 4.669| 0.710|\n",
    "| 000951 | 0.194 | 2.633| 0.568|\n",
    "| 300263 | 0.330 | 2.967| 0.609|\n",
    "| 300174 | 0.229 | 2.031| 0.746|\n",
    "| 300133 | 0.430 | 5.966| 0.785|\n",
    "| 000753 | 0.357 | 4.565| 1.047|\n",
    "| 002841 | 0.369 | 4.688| 0.713|\n",
    "| 000998 | 0.091 | 2.411| 0.367|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000753 com MAE is 0.3568296744179487, the MAPE is 4.565257975045892, the MSE is 1.0468893311222307\n",
      "300263 com MAE is 0.3301482182794872, the MAPE is 2.966666300469162, the MSE is 0.6086557043995929\n",
      "000998 com MAE is 0.0915205719877487, the MAPE is 2.4114674667919633, the MSE is 0.36674533100505274\n",
      "000951 com MAE is 0.19498004116868423, the MAPE is 2.6327771803610047, the MSE is 0.5684222432400793\n",
      "300133 com MAE is 0.4397617898415026, the MAPE is 5.966244515032575, the MSE is 0.7851925197273011\n",
      "000046 com MAE is 0.06712500368747397, the MAPE is 2.7842108061709787, the MSE is 0.4440601307134777\n",
      "002882 com MAE is 0.09368558017979427, the MAPE is 2.097611695986554, the MSE is 0.3116063670139982\n",
      "002841 com MAE is 0.3670204628341969, the MAPE is 4.669078104983375, the MSE is 0.7103900892096832\n",
      "300174 com MAE is 0.22933013198451282, the MAPE is 2.030887703447141, the MSE is 0.7463646253501821\n"
     ]
    }
   ],
   "source": [
    "result = './end_result/'\n",
    "for data_path in os.listdir(result):\n",
    "    pred_data = pd.read_csv(f'{result}{data_path}')\n",
    "    key = data_path.split('.csv')[0]\n",
    "    # com model performance\n",
    "    non_zero_mask = pred_data[f'{key}-true'] != 0\n",
    "    mape = np.mean(np.abs((pred_data[f'{key}-true'][non_zero_mask]- pred_data[f'{key}-pred'][non_zero_mask])/ (pred_data[f'{key}-true'][non_zero_mask])))\n",
    "    mae = np.mean(pred_data[f'{key}-true']- pred_data[f'{key}-pred'])\n",
    "    mse = np.mean((pred_data[f'{key}-true']- pred_data[f'{key}-pred'])** 2)\n",
    "\n",
    "    print(f\"{key} com MAE is {mae}, the MAPE is {mape}, the MSE is {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
