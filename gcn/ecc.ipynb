{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "4c6dafc2-a7e0-4cd2-a83e-5d2efe806027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\n",
    "    https://github.com/mys007/ecc\n",
    "    https://arxiv.org/abs/1704.02901\n",
    "    2017 Martin Simonovsky\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import range\n",
    "\n",
    "import igraph\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "\n",
    "    \n",
    "class GraphConvInfo(object):          \n",
    "    \"\"\" Holds information about the structure of graph(s) in a vectorized form useful to `GraphConvModule`. \n",
    "    \n",
    "    We assume that the node feature tensor (given to `GraphConvModule` as input) is ordered by igraph vertex id, e.g. the fifth row corresponds to vertex with id=4. Batch processing is realized by concatenating all graphs into a large graph of disconnected components (and all node feature tensors into a large tensor).\n",
    "\n",
    "    The class requires problem-specific `edge_feat_func` function, which receives dict of edge attributes and returns Tensor of edge features and LongTensor of inverse indices if edge compaction was performed (less unique edge features than edges so some may be reused).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self._idxn = None           #indices into input tensor of convolution (node features)\n",
    "        self._idxe = None           #indices into edge features tensor (or None if it would be linear, i.e. no compaction)\n",
    "        self._degrees = None        #in-degrees of output nodes (slices _idxn and _idxe)\n",
    "        self._degrees_gpu = None\n",
    "        self._edgefeats = None      #edge features tensor (to be processed by feature-generating network)\n",
    "        if len(args)>0 or len(kwargs)>0:\n",
    "            self.set_batch(*args, **kwargs)\n",
    "    def set_batch(self, graphs, edge_feat_func):\n",
    "        \"\"\" Creates a representation of a given batch of graphs.\n",
    "        \n",
    "        Parameters:\n",
    "        graphs: single graph or a list/tuple of graphs.\n",
    "        edge_feat_func: see class description.\n",
    "        \"\"\"\n",
    "        \n",
    "        graphs = graphs if isinstance(graphs,(list,tuple)) else [graphs]\n",
    "        p = 0\n",
    "        idxn = []\n",
    "        degrees = []\n",
    "        edgeattrs = defaultdict(list)\n",
    "                \n",
    "        for i,G in enumerate(graphs):\n",
    "            #E = np.array(G.get_edgelist())\n",
    "            E = np.array(list(G.edges()))\n",
    "            idx = E[:,1].argsort() # sort by target\n",
    "            \n",
    "            idxn.append(p + E[idx,0])\n",
    "            \n",
    "            # edgeseq = G.es[idx.tolist()]\n",
    "            # for a in G.es.attributes():\n",
    "            #     edgeattrs[a] += edgeseq.get_attribute_values(a)\n",
    "            \n",
    "            edgelist = list(graph.edges(data=False))  # Get the list of edges\n",
    "            edgeseq = [graph.get_edge_data(u, v) for u, v in edgelist]  # Get the sequence of edge data\n",
    "            # degrees += G.indegree(G.vs, loops=True)\n",
    "            # p += G.vcount()\n",
    "            degrees += list(dict(G.in_degree()).values())  # Get the in-degrees of the nodes\n",
    "            p += G.number_of_nodes()  # Accumulate the node count\n",
    "\n",
    "              \n",
    "        self._edgefeats, self._idxe = edge_feat_func(edgelist)\n",
    "        \n",
    "        self._idxn = torch.LongTensor(np.concatenate(idxn))\n",
    "        if self._idxe is not None:\n",
    "            assert self._idxe.numel() == self._idxn.numel()\n",
    "            \n",
    "        self._degrees = torch.LongTensor(degrees)\n",
    "        self._degrees_gpu = None            \n",
    "        \n",
    "    def cuda(self):\n",
    "        self._idxn = self._idxn.cuda()\n",
    "        if self._idxe is not None: self._idxe = self._idxe.cuda()\n",
    "        self._degrees_gpu = self._degrees.cuda()\n",
    "        self._edgefeats = self._edgefeats.cuda()        \n",
    "        \n",
    "    def get_buffers(self):\n",
    "        \"\"\" Provides data to `GraphConvModule`.\n",
    "        \"\"\"\n",
    "        return self._idxn, self._idxe, self._degrees, self._degrees_gpu, self._edgefeats\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "    Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs\n",
    "    https://github.com/mys007/ecc\n",
    "    https://arxiv.org/abs/1704.02901\n",
    "    2017 Martin Simonovsky\n",
    "\"\"\"\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import range\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable, Function\n",
    "import cuda_kernels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class GraphConvFunction(Function):\n",
    "    \"\"\" Computes operations for each edge and averages the results over respective nodes. The operation is either matrix-vector multiplication (for 3D weight tensors) or element-wise vector-vector multiplication (for 2D weight tensors). The evaluation is computed in blocks of size `edge_mem_limit` to reduce peak memory load. See `GraphConvInfo` for info on `idxn, idxe, degs`.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, idxn, idxe, degs, degs_gpu, edge_mem_limit=1e20):\n",
    "        super(Function, self).__init__()\n",
    "        self._in_channels = in_channels\n",
    "        self._out_channels = out_channels\n",
    "        self._idxn = idxn\n",
    "        self._idxe = idxe\n",
    "        self._degs = degs\n",
    "        self._degs_gpu = degs_gpu\n",
    "        self._shards = get_edge_shards(degs, edge_mem_limit)\n",
    "\n",
    "    def _multiply(self, a, b, out, f_a=None, f_b=None):\n",
    "        \"\"\" Performs operation on edge weights and node signal \"\"\"\n",
    "        if b.dim() == 3:\n",
    "            # weights are full in_channels x out_channels matrices -> mm\n",
    "            torch.bmm(f_a(a) if f_a else a, f_b(b) if f_b else b, out=out)\n",
    "        else:\n",
    "            # weights represent diagonal matrices -> mul\n",
    "            torch.mul(a, b.expand_as(a), out=out)\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weights, in_channels, out_channels, idxn, idxe, degs, degs_gpu, edge_mem_limit):\n",
    "        ctx.save_for_backward(input, weights)\n",
    "        ctx.in_channels = in_channels\n",
    "        ctx.out_channels = out_channels\n",
    "        ctx.idxn = idxn\n",
    "        ctx.idxe = idxe\n",
    "        ctx.degs = degs\n",
    "        ctx.degs_gpu = degs_gpu\n",
    "        ctx.edge_mem_limit = edge_mem_limit\n",
    "\n",
    "        full_weight_mat = weights.dim() == 3\n",
    "        assert full_weight_mat or (in_channels == out_channels and weights.size(1) == in_channels)\n",
    "\n",
    "        output = input.new(degs.numel(), out_channels)\n",
    "\n",
    "        # loop over blocks of output nodes\n",
    "        startd, starte = 0, 0\n",
    "        for numd, nume in get_edge_shards(degs, edge_mem_limit):\n",
    "\n",
    "            # select sequence of matching pairs of node and edge weights\n",
    "            sel_input = torch.index_select(input, 0, idxn.narrow(0, starte, nume))\n",
    "\n",
    "            if idxe is not None:\n",
    "                sel_weights = torch.index_select(weights, 0, idxe.narrow(0, starte, nume))\n",
    "            else:\n",
    "                sel_weights = weights.narrow(0, starte, nume)\n",
    "\n",
    "            # compute matrix-vector products\n",
    "            products = input.new()\n",
    "            GraphConvFunction._multiply(sel_input, sel_weights, products, lambda a: a.unsqueeze(1))\n",
    "\n",
    "            # average over nodes\n",
    "            if idxn.is_cuda:\n",
    "                cuda_kernels.conv_aggregate_fw(output.narrow(0, startd, numd), products.view(-1, out_channels),\n",
    "                                                degs_gpu.narrow(0, startd, numd))\n",
    "            else:\n",
    "                k = 0\n",
    "                for i in range(startd, startd + numd):\n",
    "                    if degs[i] > 0:\n",
    "                        torch.mean(products.narrow(0, k, degs[i]), 0, out=output[i])\n",
    "                    else:\n",
    "                        output[i].fill_(0)\n",
    "                    k = k + degs[i]\n",
    "\n",
    "            startd += numd\n",
    "            starte += nume\n",
    "            del sel_input, sel_weights, products\n",
    "\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, weights = ctx.saved_tensors\n",
    "\n",
    "        grad_input = input.new(input.size()).fill_(0)\n",
    "        grad_weights = weights.new(weights.size())\n",
    "        if ctx.idxe is not None:\n",
    "            grad_weights.fill_(0)\n",
    "\n",
    "        # loop over blocks of output nodes\n",
    "        startd, starte = 0, 0\n",
    "        for numd, nume in get_edge_shards(ctx.degs, ctx.edge_mem_limit):\n",
    "\n",
    "            grad_products, tmp = input.new(nume, ctx.out_channels), input.new()\n",
    "\n",
    "            if ctx.idxn.is_cuda:\n",
    "                cuda_kernels.conv_aggregate_bw(grad_products, grad_output.narrow(0, startd, numd),\n",
    "                                                ctx.degs_gpu.narrow(0, startd, numd))\n",
    "            else:\n",
    "                k = 0\n",
    "                for i in range(startd, startd + numd):\n",
    "                    if ctx.degs[i] > 0:\n",
    "                        torch.div(grad_output[i], ctx.degs[i], out=grad_products[k])\n",
    "                        if ctx.degs[i] > 1:\n",
    "                            grad_products.narrow(0, k + 1, ctx.degs[i] - 1).copy_(\n",
    "                                grad_products[k].expand(ctx.degs[i] - 1, 1, ctx.out_channels).squeeze(1))\n",
    "                        k = k + ctx.degs[i]\n",
    "\n",
    "            # grad wrt weights\n",
    "            sel_input = torch.index_select(input, 0, ctx.idxn.narrow(0, starte, nume))\n",
    "\n",
    "            if ctx.idxe is not None:\n",
    "                GraphConvFunction._multiply(sel_input, grad_products, tmp, lambda a: a.unsqueeze(1).transpose_(2, 1),\n",
    "                                            lambda b: b.unsqueeze(1))\n",
    "                grad_weights.index_add_(0, ctx.idxe.narrow(0, starte, nume), tmp)\n",
    "            else:\n",
    "                GraphConvFunction._multiply(sel_input, grad_products, grad_weights.narrow(0, starte, nume),\n",
    "                                            lambda a: a.unsqueeze(1).transpose_(2, 1), lambda b: b.unsqueeze(1))\n",
    "\n",
    "            # grad wrt input\n",
    "            if ctx.idxe is not None:\n",
    "                torch.index_select(weights, 0, ctx.idxe.narrow(0, starte, nume), out=tmp)\n",
    "                GraphConvFunction._multiply(grad_products, tmp, sel_input, lambda a: a.unsqueeze(1),\n",
    "                                            lambda b: b.transpose(2, 1))\n",
    "                del tmp\n",
    "            else:\n",
    "                GraphConvFunction._multiply(grad_products, weights.narrow(0, starte, nume), sel_input,\n",
    "                                            lambda a: a.unsqueeze(1), lambda b: b.transpose(2, 1))\n",
    "\n",
    "        return grad_input, grad_weights, None, None, None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "26dd0d8e-edb0-4550-9cf4-889c92bbb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvModule(nn.Module):\n",
    "    \"\"\" Computes graph convolution using filter weights obtained from a filter generating network (`filter_net`).\n",
    "        The input should be a 2D tensor of size (# nodes, `in_channels`). Multiple graphs can be concatenated in the same tensor (minibatch).\n",
    "    \n",
    "    Parameters:\n",
    "    in_channels: number of input channels\n",
    "    out_channels: number of output channels\n",
    "    filter_net: filter-generating network transforming a 2D tensor (# edges, # edge features) to (# edges, in_channels*out_channels) or (# edges, in_channels)\n",
    "    gc_info: GraphConvInfo object containing graph(s) structure information, can be also set with `set_info()` method.\n",
    "    edge_mem_limit: block size (number of evaluated edges in parallel) for convolution evaluation, a low value reduces peak memory. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, filter_net, gc_info=None, edge_mem_limit=1e20):\n",
    "        super(GraphConvModule, self).__init__()\n",
    "        \n",
    "        self._in_channels = in_channels\n",
    "        self._out_channels = out_channels\n",
    "        self._fnet = filter_net\n",
    "        self._edge_mem_limit = edge_mem_limit\n",
    "        \n",
    "        self.set_info(gc_info)\n",
    "        \n",
    "    def set_info(self, gc_info):\n",
    "        self._gci = gc_info\n",
    "    \n",
    "    def forward(self, input):       \n",
    "        # get graph structure information tensors\n",
    "        idxn, idxe, degs, degs_gpu, edgefeats = self._gci.get_buffers()\n",
    "        edgefeats = Variable(edgefeats, requires_grad=False)\n",
    "        \n",
    "        # evalute and reshape filter weights\n",
    "        weights = self._fnet(edgefeats)\n",
    "        print(input.dim())\n",
    "        print(weights.shape)\n",
    "        assert input.dim()==2 and weights.dim()==2 and (weights.size(1) == self._in_channels*self._out_channels or\n",
    "               (self._in_channels == self._out_channels and weights.size(1) == self._in_channels))\n",
    "        if weights.size(1) == self._in_channels*self._out_channels:\n",
    "            weights = weights.view(-1, self._in_channels, self._out_channels)\n",
    "        return GraphConvFunction.apply(input, weights, self._in_channels, self._out_channels, idxn, idxe, degs, degs_gpu, self._edge_mem_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "d28c8b18-90d2-49d2-9e40-9cb3c77871ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP\n",
    "def create_fnet(widths, nfeat, nfeato, orthoinit, llbias):\n",
    "    \"\"\" Creates feature-generating network, a multi-layer perceptron.\n",
    "    Parameters:\n",
    "    widths: list of widths of hidden layers\n",
    "    nfeat, nfeato: # input and output channels of the convolution\n",
    "    orthoinit: whether to use orthogonal weight initialization\n",
    "    llbias: whether to use bias in the last layer\n",
    "    \"\"\"\n",
    "    fnet_modules = []   \n",
    "    for k in range(len(widths)-1):\n",
    "        fnet_modules.append(nn.Linear(widths[k], widths[k+1]))\n",
    "        if orthoinit: init.orthogonal(fnet_modules[-1].weight, gain=init.calculate_gain('relu'))\n",
    "        fnet_modules.append(nn.ReLU(True))                    \n",
    "    fnet_modules.append(nn.Linear(widths[-1], nfeat*nfeato, bias=llbias))\n",
    "    if orthoinit: init.orthogonal(fnet_modules[-1].weight)\n",
    "    return nn.Sequential(*fnet_modules)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "e9363f25-35f9-40fb-8b46-ff82920a072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_shards(degs, edge_mem_limit):\n",
    "    \"\"\" Splits iteration over nodes into shards, approximately limited by `edge_mem_limit` edges per shard. \n",
    "    Returns a list of pairs indicating how many output nodes and edges to process in each shard.\"\"\"\n",
    "    d = degs if isinstance(degs, np.ndarray) else degs.numpy()\n",
    "    cs = np.cumsum(d)\n",
    "    cse = cs // edge_mem_limit\n",
    "    _, cse_i, cse_c = np.unique(cse, return_index=True, return_counts=True)\n",
    "    \n",
    "    shards = []\n",
    "    for b in range(len(cse_i)):\n",
    "        numd = cse_c[b]\n",
    "        nume = (cs[-1] if b==len(cse_i)-1 else cs[cse_i[b+1]-1]) - cs[cse_i[b]] + d[cse_i[b]]   \n",
    "        shards.append( (int(numd), int(nume)) )\n",
    "    return shards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "c53f5db4-668a-4139-bfab-151094c0830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjacency_matrix_to_edges(adjacency_matrix):\n",
    "    edges = []\n",
    "    num_nodes = adjacency_matrix.shape[0]\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if adjacency_matrix[i, j] != 0:\n",
    "                edges.append((i, j))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "d225d361-b63f-4bf9-bbca-81639068691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj=np.load('/volume1/home/rzhu/gcn/data/volume/0308/000046_XSHE_3_3_graph_input.npy')\n",
    "edges=adjacency_matrix_to_edges(adj_transposed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "74d04c98-70af-4865-bb11-957bfd65cc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1), (0, 4), (0, 5), (1, 1), (1, 2), (1, 6), (1, 12), (2, 2), (2, 3), (2, 7), (2, 13), (3, 3), (3, 14), (4, 4), (4, 5), (4, 8), (4, 9), (5, 5), (5, 6), (5, 10), (6, 6), (6, 7), (6, 11), (7, 7), (8, 8), (8, 9), (8, 12), (8, 13), (9, 9), (9, 10), (9, 14), (10, 10), (10, 11), (10, 15), (11, 11), (12, 12), (12, 13), (13, 13), (13, 14), (14, 14), (14, 15)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "adj_transposed = np.transpose(adj)\n",
    "# Your adjacency matrix\n",
    "adjacency_matrix = np.array(adj_transposed)\n",
    "# Create a directed graph from the adjacency matrix\n",
    "graph = nx.DiGraph(adjacency_matrix)\n",
    "print(graph.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "18235271-fb6f-444e-874d-047d4ec447ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def edge_feat_func(edges):\n",
    "    edge_dict = {}  # 用于存储边的差异及其对应的索引\n",
    "    idxe = []  # 用于存储边特征的索引\n",
    "    edgefeats = []  # 用于存储边特征的 one-hot 编码\n",
    "\n",
    "    # 遍历边列表，计算边的差异并将其分类\n",
    "    for edge in edges:\n",
    "        diff = edge[1] - edge[0]  # 计算边的差异\n",
    "        if diff not in edge_dict:\n",
    "            edge_dict[diff] = len(edge_dict)  # 如果差异之前没有出现过，则添加到字典中\n",
    "        idxe.append(edge_dict[diff])  # 将差异的索引添加到 idxe 中\n",
    "\n",
    "    # 构建 one-hot 编码的边特征\n",
    "    num_features = len(edge_dict)\n",
    "    seen_feats = set()  # 用于记录已经出现过的特征索引\n",
    "    for idx in idxe:\n",
    "        if idx not in seen_feats:  # 检查特征索引是否已经存在于集合中\n",
    "            feat = torch.zeros(num_features)\n",
    "            feat[idx] = 1\n",
    "            edgefeats.append(feat)\n",
    "            seen_feats.add(idx)  # 将特征索引添加到集合中\n",
    "\n",
    "    return torch.stack(edgefeats), torch.LongTensor(idxe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "2174d98c-8089-46b1-bfec-9c5841ab8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgefeats= edge_feat_func(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "33a3f6a7-43ac-4d04-9f2b-b612c0d57d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge Features:\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "Index List:\n",
      "tensor([0, 1, 2, 3, 0, 1, 3, 4, 0, 1, 3, 4, 0, 4, 0, 1, 2, 3, 0, 1, 3, 0, 1, 3,\n",
      "        0, 0, 1, 2, 3, 0, 1, 3, 0, 1, 3, 0, 0, 1, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "edgefeats, idxe = edge_feat_func(edges) \n",
    "print(\"Edge Features:\")\n",
    "print(edgefeats)\n",
    "print(\"Index List:\")\n",
    "print(idxe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "7c49f6d6-891f-49ee-8d19-2514b5fa9e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_info = GraphConvInfo()\n",
    "gc_info.set_batch(graph, edge_feat_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "4dc54d8a-3e52-4666-bf2b-44137fea078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2051659/3782370251.py:13: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
      "  if orthoinit: init.orthogonal(fnet_modules[-1].weight, gain=init.calculate_gain('relu'))\n",
      "/tmp/ipykernel_2051659/3782370251.py:16: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
      "  if orthoinit: init.orthogonal(fnet_modules[-1].weight)\n"
     ]
    }
   ],
   "source": [
    "fnet = create_fnet([5,5], 1, 1, 1, 1)\n",
    "gconv = GraphConvModule(7, 7, fnet, edge_mem_limit=1e20)\n",
    "gconv.set_info(gc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "9279d8c5-c696-4ebd-a65f-446e4e78dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_data=np.load('/volume1/home/rzhu/gcn/data/volume/0308/000046_XSHE_3_3_inputs.npy', allow_pickle=True)\n",
    "inputs_data = [[[torch.tensor(x, dtype=torch.float64) for x in sublist] for sublist in list1] for list1 in inputs_data]\n",
    "array_data = np.array(inputs_data)\n",
    "inputs = np.reshape(array_data, (len(inputs_data), 16,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "7d41c97c-bf45-44fa-9f39-5ff7ed15bfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 7)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "21e01d93-91e5-403d-b797-326c8183b572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 7])"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_tensor = torch.tensor(inputs[0], dtype=torch.float32)\n",
    "inputs_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "929027e3-4f44-45c2-bb23-00034aa32b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([5, 1])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[527], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mgconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/bioinfo/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[506], line 35\u001b[0m, in \u001b[0;36mGraphConvModule.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim())\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(weights\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m weights\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (weights\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_channels\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_channels \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m     36\u001b[0m        (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_channels \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_channels \u001b[38;5;129;01mand\u001b[39;00m weights\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_channels))\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_channels\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_channels:\n\u001b[1;32m     38\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_channels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_out_channels)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "output = gconv(inputs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435538d-e59c-4f80-9948-b328e5a03b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60760828-6c81-4208-a89c-aa965f736c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd27272a-e7b7-4924-9c0c-bac2a1325bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo",
   "language": "python",
   "name": "bioinfo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
