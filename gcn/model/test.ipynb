{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diff_bin(data):\n",
    "    average_bin, bin_0, bin_24 = [], [], []\n",
    "\n",
    "    for row in range(24, data.shape[0], 25):\n",
    "        bin_24.append(data.loc[row, 'bin_volume'])\n",
    "\n",
    "    for row in range(0, data.shape[0], 25):\n",
    "        bin_0.append(data.loc[row, 'bin_volume'])\n",
    "        average_bin.append(data.loc[row+ 1: row+ 24, 'daily_volume'].mean())\n",
    "    return average_bin, bin_0, bin_24\n",
    "\n",
    "\n",
    "def transformer(data):\n",
    "    transformed_nums = [-1 if num < 0 else 1 if num > 0 else 0 for num in data]\n",
    "    return transformed_nums\n",
    "\n",
    "average_bin, bin_0, bin_24 = get_diff_bin(data_46)\n",
    "# print(len(average_bin), len(bin_0), len(bin_24))\n",
    "\n",
    "diff_average_bin = transformer([(average_bin[i] - average_bin[i-1]) for i in range(1, len(average_bin))])\n",
    "diff_bin_0_24 = [bin_0[i]- bin_24[i] for i in range(len(bin_24))][1:]\n",
    "diff_bin_0_0 = [(bin_0[i]- bin_0[i-1])/bin_0[i-1] for i in range(1, len(bin_0))]\n",
    "# print(len(diff_average_bin), len(diff_bin_0_0), len(diff_bin_0_24))\n",
    "\n",
    "data_diff = pd.DataFrame({'ddiff_average_bin': diff_average_bin, 'bin_0_0': diff_bin_0_0, 'bin_0_24': diff_bin_0_24})\n",
    "# data_diff.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 24)\n"
     ]
    }
   ],
   "source": [
    "def df2matrix(file_path:str, col_name: str=None, bin_num: bool= True):\n",
    "    \"\"\"\n",
    "    转换数据结构，以date为横坐标，制定col_name为纵坐标\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "    df.set_index('date', inplace= True)\n",
    "    df.sort_index(inplace= True)\n",
    "    n, k = df.shape[0], 25\n",
    "    # TODO: 1、把 bin0 分离出来，而后补充到特征里面去，也就是需要在  self.genNewFeatureBinVolume() 把bin0 特征融合进来\n",
    "    if bin_num:\n",
    "        data = pd.DataFrame(np.array(df[col_name]).reshape(int(n/k), k),\n",
    "                                columns= ['bin{}'.format(i) for i in range(k)]).drop('bin0', axis=1)\n",
    "    else:\n",
    "        bin0_list = []\n",
    "        for i in range(0, df.shape[0], 25):\n",
    "            if i == 0:\n",
    "                bin0_list.append([(df[col_name].iloc[i]- df[col_name].iloc[i])/ df[col_name].iloc[i]])\n",
    "            else:\n",
    "                bin0_list.append([(df[col_name].iloc[i]- df[col_name].iloc[i-25])/ df[col_name].iloc[i-25]])\n",
    "        result = np.array([[element[0]]*(k-1) for element in bin0_list])\n",
    "        print(result.shape)\n",
    "        data = pd.DataFrame(np.array(result),\n",
    "                            columns= ['bin0' for i in range(k-1)])\n",
    "    data['date'] = pd.to_datetime(list(sorted(set(df.index))), format='%Y/%m/%d')\n",
    "    data.set_index('date', inplace= True)\n",
    "    data.sort_index(inplace=True)\n",
    "    return data\n",
    "\n",
    "data = df2matrix(file_path= '../data/0308/000046_XSHE_25_daily.csv', col_name= 'bin_volume', bin_num= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/comment/000046.csv')\n",
    "df2 = pd.read_csv('../data/0308/000046_XSHE_25_daily.csv')\n",
    "# df2['date'] = pd.to_datetime(df2['date'])\n",
    "# df2['date'] = df2['date'].dt.date\n",
    "df['publishDate'] = pd.to_datetime(df['publishDate'])\n",
    "\n",
    "start_time = '2020-5-12 15:00'\n",
    "end_time = '2021-3-8 15:00'\n",
    "filtered_df = df[(df['publishDate'] >= start_time) & (df['publishDate'] <= end_time)].copy().reset_index(drop=True)\n",
    "filtered_df['dates'] = filtered_df['publishDate'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>publishDate</th>\n",
       "      <th>newsTitle</th>\n",
       "      <th>posterId</th>\n",
       "      <th>posterName</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>929174946</td>\n",
       "      <td>2020-05-12 15:07:40</td>\n",
       "      <td>泛海下跌周期太长，被套资本太多，没有啥机会暴涨的，就像上次一样涨到8元就被打熄火</td>\n",
       "      <td>5323335728465078</td>\n",
       "      <td>股友oRx5gP</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929207943</td>\n",
       "      <td>2020-05-12 17:26:28</td>\n",
       "      <td>民生证券将挥别北京 泛海控股再度布局上海滩</td>\n",
       "      <td>4506395531315256</td>\n",
       "      <td>投资者攻略</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>929210791</td>\n",
       "      <td>2020-05-12 17:39:29</td>\n",
       "      <td>适合在家创业的6个项目，有适合您的吗？</td>\n",
       "      <td>7301305858084640</td>\n",
       "      <td>小息谈资讯</td>\n",
       "      <td>2020-05-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>929323847</td>\n",
       "      <td>2020-05-13 06:01:54</td>\n",
       "      <td>泛海，真的跌得好惨！</td>\n",
       "      <td>9273094111979056</td>\n",
       "      <td>水中月7878</td>\n",
       "      <td>2020-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>929331305</td>\n",
       "      <td>2020-05-13 06:49:52</td>\n",
       "      <td>看看大盘走的多好，震荡上行，好多个股都跌惨了，什么破股市啊</td>\n",
       "      <td>3407145336565478</td>\n",
       "      <td>魅力的林顺昊</td>\n",
       "      <td>2020-05-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     post_id         publishDate                                 newsTitle  \\\n",
       "0  929174946 2020-05-12 15:07:40  泛海下跌周期太长，被套资本太多，没有啥机会暴涨的，就像上次一样涨到8元就被打熄火   \n",
       "1  929207943 2020-05-12 17:26:28                     民生证券将挥别北京 泛海控股再度布局上海滩   \n",
       "2  929210791 2020-05-12 17:39:29                       适合在家创业的6个项目，有适合您的吗？   \n",
       "3  929323847 2020-05-13 06:01:54                                泛海，真的跌得好惨！   \n",
       "4  929331305 2020-05-13 06:49:52             看看大盘走的多好，震荡上行，好多个股都跌惨了，什么破股市啊   \n",
       "\n",
       "           posterId posterName       dates  \n",
       "0  5323335728465078   股友oRx5gP  2020-05-12  \n",
       "1  4506395531315256      投资者攻略  2020-05-12  \n",
       "2  7301305858084640      小息谈资讯  2020-05-12  \n",
       "3  9273094111979056    水中月7878  2020-05-13  \n",
       "4  3407145336565478     魅力的林顺昊  2020-05-13  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-5-12\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "# 创建一个日期对象\n",
    "date_obj = date(2020, 5, 12)\n",
    "\n",
    "# 手动格式化日期为 \"YYYY-M-D\" 格式\n",
    "formatted_date_custom = f\"{date_obj.year}-{date_obj.month}-{date_obj.day}\"\n",
    "print(formatted_date_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_XSHE = set(df2['date'])\n",
    "date_XSHE.add(str(filtered_df.loc[0, 'dates']))\n",
    "date_XSHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_bins(day):\n",
    "    bins = {}\n",
    "    # bin_0: 从前一天的15:00到当天的09:30\n",
    "    bin_0_start = f'{day - pd.Timedelta(days=1)} 15:00'\n",
    "    bin_0_end = f'{day} 09:30'\n",
    "    bins['bin0'] = [bin_0_start, bin_0_end]\n",
    "\n",
    "    # 初始化bin_1的起始时间为bin_0的结束时间\n",
    "    current_start = bin_0_end\n",
    "\n",
    "    # 循环生成剩下的23个bin\n",
    "    for i in range(1, 25):\n",
    "        if i == 10:\n",
    "            bins[f'bin{i}'] = [current_start, f'{day} 11:30']\n",
    "            current_start = f'{day} 11:30'\n",
    "        elif i == 11:\n",
    "            bins[f'bin{i}'] = [f'{day} 11:30', f'{day} 13:00']\n",
    "            current_start = f'{day} 13:00'\n",
    "        elif i == 24:\n",
    "            bins[f'bin{i}'] = [current_start, f'{day} 15:00']\n",
    "        else:\n",
    "            current_end = pd.to_datetime(current_start) + pd.Timedelta(minutes=9.875)\n",
    "            bins[f'bin{i}'] = [current_start, current_end.strftime('%Y-%m-%d %H:%M')]\n",
    "            current_start = current_end.strftime('%Y-%m-%d %H:%M')\n",
    "    return bins\n",
    "\n",
    "times_set = set()\n",
    "for i in filtered_df['dates']:\n",
    "    times_set.add(i)\n",
    "\n",
    "data_bin = pd.DataFrame(index = list(date_XSHE),\n",
    "                        columns= [f'bin{i}' for i in range(0, 25)])\n",
    "data_bin.index = pd.to_datetime(data_bin.index)\n",
    "data_bin = data_bin.sort_index(ascending= True)\n",
    "for day in data_bin.index[1:]:\n",
    "    # print()\n",
    "    if str(day.date()) in date_XSHE:\n",
    "        bin_newstitle = {}\n",
    "        bins = calculate_time_bins(day.date())\n",
    "        for bin in bins:\n",
    "            bin_newstitle[bin] = filtered_df[(filtered_df['publishDate'] >= bins[bin][0]) & (filtered_df['publishDate'] <= bins[bin][1])].loc[:, 'newsTitle'].values\n",
    "        data_bin.loc[day] = bin_newstitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['泛海不用借壳只用整体上市及少付利息就可做到利润80亿到一百多亿的混合金融，投资及'\n",
      " '很早捐几十亿的，投资民生银行，海通，蚂蚁等几十独角兽的，二十年囤核心城市核心地的' '民生证券过会8单' '明天应该要收复3.91'\n",
      " '混合金融业绩一到三元角股是目标，分红毎年一到五角是目标，最终比卢总强的企业家没几'\n",
      " '1月14日，503涨停，我卖来马上反悔了，马上挂单买怎么也买不到，15年我20融' '这两天有点强[赞]'\n",
      " '中国人节俭爱投资创业，最终金融全牌照几十独角兽盈利能力会超九成快消企业及95％的' '弱反弹而已到4.5再说'\n",
      " '根据中央商务引战46亿时仔细评估升值378亿后，中美土地物业房地产涨了不少，蚂蚁'\n",
      " '30岁的经理喜欢高价呼人的，其实低价值值股业绩股分红股只要涨一点点差价比例大，数'] \n",
      " -1\n",
      "['-1', '0', '0', '0', '0', '-1', '-1', '0', '-1', '-1', '0', '-1', '-1', '0', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '-1', '']\n",
      "invalid literal for int() with base 10: ''\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def prompt_build():\n",
    "    prompt = f\"作为情感分析专家，请根据以下输入文本判断评论的情感态度。\\\n",
    "        要求:\\\n",
    "            1.情感态度表示方式：消极:-1，积极:1，中性:0\\\n",
    "            2.请直接返回对应的数字，无需提供额外解释\\\n",
    "        示例:'这只股票要完了'.输出:-1\\\n",
    "        请分析以下文本的情感态度:\"\n",
    "    return prompt\n",
    "\n",
    "def ZhiPuSentiment(input_comment: str,\n",
    "                api_key: str= 'daadb0e4e98a27cb82436c0f321eeb53.GtyK1RkdCkzhxt4V'):\n",
    "    client = ZhipuAI(\n",
    "        api_key= api_key\n",
    "    )\n",
    "    prompt = prompt_build()\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"glm-3-turbo\",\n",
    "        messages= [\n",
    "            {'role': \"user\", \"content\": prompt+ input_comment},\n",
    "        ],\n",
    "        temperature = 0.3,\n",
    "    )\n",
    "    # print(response.choices[0].message.content, input_comment)\n",
    "    sentiment_scores = []\n",
    "    print(response.choices[0].message.content.replace(' ', '').split(','))\n",
    "    for score in  response.choices[0].message.content.replace(' ', '').split(','):\n",
    "        try:\n",
    "            sentiment_scores.append(int(score))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    # print(sentiment_scores)\n",
    "    score = max(sentiment_scores, key= sentiment_scores.count)\n",
    "    return score\n",
    "\n",
    "\n",
    "df = pd.read_csv('../data/0308/0308-comment/000046_comment.csv', index_col='Unnamed: 0')\n",
    "df2 = pd.read_csv('../data/0308/0303-number/000046_comment_sentiment.csv', index_col='Unnamed: 0')\n",
    "i, j = 19, 0\n",
    "print(df.iloc[i, j], '\\n', df2.iloc[i, j])\n",
    "ZhiPuSentiment(input_comment= df.iloc[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['泛海下跌周期太长，被套资本太多，没有啥机会暴涨的，就像上次一样涨到8元就被打熄火' '民生证券将挥别北京 泛海控股再度布局上海滩'\n",
      " '适合在家创业的6个项目，有适合您的吗？' '泛海，真的跌得好惨！' '看看大盘走的多好，震荡上行，好多个股都跌惨了，什么破股市啊'\n",
      " '泛海控股05月12日获深股通减仓27.45万股']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/0308/0308-comment/000046_comment.csv')\n",
    "print(df.iloc[0, 1])\n",
    "# for i in df.iloc[0,1].replace(\"[\", '').replace(\"]\",'').strip().split(' '):\n",
    "# for i in df.iloc[0, 1].replace(\"[\", '').replace(\"]\",''):\n",
    "    # print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000998_comment'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '../data/0308/0308-comment/000998_comment.csv'\n",
    "a[26:len(a)-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bin0': ['2021-03-07 15:00', '2021-03-08 09:30'],\n",
       " 'bin1': ['2021-03-08 09:30', '2021-03-08 09:39'],\n",
       " 'bin2': ['2021-03-08 09:39', '2021-03-08 09:48'],\n",
       " 'bin3': ['2021-03-08 09:48', '2021-03-08 09:57'],\n",
       " 'bin4': ['2021-03-08 09:57', '2021-03-08 10:06'],\n",
       " 'bin5': ['2021-03-08 10:06', '2021-03-08 10:15'],\n",
       " 'bin6': ['2021-03-08 10:15', '2021-03-08 10:24'],\n",
       " 'bin7': ['2021-03-08 10:24', '2021-03-08 10:33'],\n",
       " 'bin8': ['2021-03-08 10:33', '2021-03-08 10:42'],\n",
       " 'bin9': ['2021-03-08 10:42', '2021-03-08 10:51'],\n",
       " 'bin10': ['2021-03-08 10:51', '2021-03-08 11:30'],\n",
       " 'bin11': ['2021-03-08 11:30', '2021-03-08 13:00'],\n",
       " 'bin12': ['2021-03-08 13:00', '2021-03-08 13:09'],\n",
       " 'bin13': ['2021-03-08 13:09', '2021-03-08 13:18'],\n",
       " 'bin14': ['2021-03-08 13:18', '2021-03-08 13:27'],\n",
       " 'bin15': ['2021-03-08 13:27', '2021-03-08 13:36'],\n",
       " 'bin16': ['2021-03-08 13:36', '2021-03-08 13:45'],\n",
       " 'bin17': ['2021-03-08 13:45', '2021-03-08 13:54'],\n",
       " 'bin18': ['2021-03-08 13:54', '2021-03-08 14:03'],\n",
       " 'bin19': ['2021-03-08 14:03', '2021-03-08 14:12'],\n",
       " 'bin20': ['2021-03-08 14:12', '2021-03-08 14:21'],\n",
       " 'bin21': ['2021-03-08 14:21', '2021-03-08 14:30'],\n",
       " 'bin22': ['2021-03-08 14:30', '2021-03-08 14:39'],\n",
       " 'bin23': ['2021-03-08 14:39', '2021-03-08 14:48'],\n",
       " 'bin24': ['2021-03-08 14:48', '2021-03-08 15:00']}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
