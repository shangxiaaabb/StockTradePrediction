{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "346d7663-efeb-468e-baad-ba380c3e5b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f5d96d7d040>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import GCNConv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn.init as init\n",
    "import pdb\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e71bae64-c20e-4b93-8e9c-20e6703af300",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def file_name(file_dir,file_type='.csv'):#默认为文件夹下的所有文件\n",
    "    lst = []\n",
    "    for root, dirs, files in os.walk(file_dir):\n",
    "        for file in files:\n",
    "            if(file_type == ''):\n",
    "                lst.append(file)\n",
    "            else:\n",
    "                if os.path.splitext(file)[1] == str(file_type):#获取指定类型的文件名\n",
    "                    lst.append(file)\n",
    "    return lst\n",
    "\n",
    "def normalize0(inputs):\n",
    "    normalized = []\n",
    "    for eq in inputs:\n",
    "        maks = np.max(np.abs(eq))\n",
    "        if maks != 0:\n",
    "            normalized.append(eq / maks)\n",
    "        else:\n",
    "            normalized.append(eq)\n",
    "    return np.array(normalized)\n",
    "\n",
    "\n",
    "def normalize1(inputs):\n",
    "    normalized = []\n",
    "    for eq in inputs:\n",
    "        mean = np.mean(eq)\n",
    "        std = np.std(eq)\n",
    "        if std != 0:\n",
    "            normalized.append((eq - mean) / std)\n",
    "        else:\n",
    "            normalized.append(eq)\n",
    "    return np.array(normalized)\n",
    "\n",
    "\n",
    "def normalize(inputs):\n",
    "    normalized = []\n",
    "    for eq in inputs:\n",
    "        with np.errstate(invalid='ignore'):\n",
    "            eps = 1e-10  # 可以根据需要调整epsilon的值\n",
    "\n",
    "            eq_log = [np.log(x + eps) if i < 5 else x for i, x in enumerate(eq)]\n",
    "\n",
    "            #eq_log = [np.log(x) if i < 5 else x for i, x in enumerate(eq)]\n",
    "            eq_log1 = np.nan_to_num(eq_log).tolist()\n",
    "            normalized.append(eq_log1)\n",
    "    return np.array(normalized)\n",
    "\n",
    "\n",
    "def k_fold_split(inputs, targets, K, seed=None):\n",
    "    # 确保所有随机操作都使用相同的种子\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    ind = int(len(inputs) / K)\n",
    "    inputsK = []\n",
    "    targetsK = []\n",
    "\n",
    "    for i in range(0, K - 1):\n",
    "        inputsK.append(inputs[i * ind:(i + 1) * ind])\n",
    "        targetsK.append(targets[i * ind:(i + 1) * ind])\n",
    "\n",
    "    inputsK.append(inputs[(i + 1) * ind:])\n",
    "    targetsK.append(targets[(i + 1) * ind:])\n",
    "\n",
    "    return inputsK, targetsK\n",
    "\n",
    "\n",
    "def merge_splits(inputs, targets, k, K):\n",
    "    if k != 0:\n",
    "        z = 0\n",
    "        inputsTrain = inputs[z]\n",
    "        targetsTrain = targets[z]\n",
    "    else:\n",
    "        z = 1\n",
    "        inputsTrain = inputs[z]\n",
    "        targetsTrain = targets[z]\n",
    "\n",
    "    for i in range(z + 1, K):\n",
    "        if i != k:\n",
    "            inputsTrain = np.concatenate((inputsTrain, inputs[i]))\n",
    "            targetsTrain = np.concatenate((targetsTrain, targets[i]))\n",
    "\n",
    "    return inputsTrain, targetsTrain, inputs[k], targets[k]\n",
    "\n",
    "\n",
    "def targets_to_list(targets):\n",
    "    targetList = np.array(targets)\n",
    "\n",
    "    return targetList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cccd0ca3-033b-4444-b1b1-963d07f8f6eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    \"\"\"Graph Convolutional Network\"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out):#[7,16,1]\n",
    "        super().__init__()\n",
    "        reg_const=0.0001\n",
    "        self.gcn1 = GCNConv(dim_in, dim_h,weight_decay=reg_const,node_dim=1)\n",
    "        self.gcn2 = GCNConv(dim_h, dim_h,weight_decay=reg_const,node_dim=1)\n",
    "        self.gcn3 = GCNConv(dim_h, dim_h,bias=True,weight_decay=reg_const,node_dim=1)\n",
    "        self.linear2 = torch.nn.Linear(dim_h, 8).double() \n",
    "        self.linear3 = torch.nn.Linear(8, dim_out).double() \n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        for layer in [self.gcn1, self.gcn2, self.gcn3, self.linear2, self.linear3]:\n",
    "            if isinstance(layer, torch.nn.Linear):\n",
    "                init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    init.zeros_(layer.bias)\n",
    "            elif isinstance(layer, GCNConv):\n",
    "                # For GCNConv, handle weight and bias separately\n",
    "                init.xavier_uniform_(layer.lin.weight)\n",
    "                if layer.bias is not None:\n",
    "                    init.zeros_(layer.bias)\n",
    "\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x=x.double()\n",
    "        edge_index = torch.stack([np.nonzero(t)for t in torch.unbind(adj,dim=0)],dim=0).permute(0,2,1)\n",
    "        edge_index=edge_index[0][[1, 0], :]\n",
    "        print(edge_index.shape)\n",
    "        self.gcn1 = self.gcn1.to(torch.double)\n",
    "        self.gcn2 = self.gcn2.to(torch.double)\n",
    "        self.gcn3 = self.gcn3.to(torch.double)\n",
    "        h = self.gcn1(x, edge_index)\n",
    "        h = torch.nn.LeakyReLU()(h)\n",
    "        h = self.gcn2(h, edge_index)\n",
    "        h = torch.nn.LeakyReLU()(h)\n",
    "        h = self.gcn3(h, edge_index)\n",
    "        h = torch.nn.LeakyReLU()(h)\n",
    "        last_column = h[:, -1]\n",
    "        conv1_new = last_column.unsqueeze(-1)\n",
    "        #conv1_new = torch.nn.Flatten(conv1_new)\n",
    "        #conv1_new = F.dropout(conv1_new,p=0.3)\n",
    "        conv1_new = F.dropout(conv1_new.view(conv1_new.size(0), -1), p=0.3, training=self.training) \n",
    "        conv1_new = self.linear2(conv1_new)\n",
    "        y_hat = self.linear3(conv1_new)\n",
    "        return y_hat\n",
    "\n",
    "\n",
    "    def fit(self,train_loader, val_loader,num_epochs=5000, patience=100):\n",
    "        #best_val_loss = float('inf')\n",
    "        best_val_loss = torch.tensor(float('inf'), dtype=torch.double)\n",
    "        patience_counter = 0\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.0015,weight_decay=5e-4)\n",
    "        criterion = nn.MSELoss()\n",
    "        # 使用平滑的 L1 损失，也称为 Huber loss\n",
    "        # criterion = nn.SmoothL1Loss()\n",
    "\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            train_loss = 0.0 \n",
    "            for inputs, graph_input, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs, graph_input)\n",
    "                loss = criterion(outputs, targets.unsqueeze(1))\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm = 1)\n",
    "                optimizer.step()\n",
    "            #     train_loss += loss.item()\n",
    "            # avg_train_loss = train_loss / len(train_loader)\n",
    "            \n",
    "\n",
    "            self.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for val_inputs, val_graph_input, val_targets in val_loader:\n",
    "                    val_outputs = self(val_inputs, val_graph_input)\n",
    "                    val_loss = criterion(val_outputs, val_targets.unsqueeze(1))\n",
    "            #         val_loss += val_loss.item()\n",
    "            # avg_val_loss=val_loss / len(val_loader)\n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "                \n",
    "\n",
    "            # Early stopping\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f'Early stopping at epoch {epoch+1}')\n",
    "                    return\n",
    "                \n",
    "                \n",
    "    def test(self,test_loader):\n",
    "        self.eval()\n",
    "        predictions = []\n",
    "        for test_inputs, test_graph_input, _ in test_loader:\n",
    "            batch_predictions = self(test_inputs, test_graph_input)\n",
    "            predictions.append(batch_predictions)\n",
    "        predictions = torch.cat(predictions)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13076a9f-90ee-411e-83b2-0454921d17ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000046_XSHE', '000753_XSHE', '000951_XSHE', '000998_XSHE', '002282_XSHE', '002679_XSHE', '002841_XSHE', '002882_XSHE', '300133_XSHE', '300174_XSHE', '300263_XSHE', '300343_XSHE', '300433_XSHE', '300540_XSHE', '600622_XSHG', '603053_XSHG', '603095_XSHG', '603359_XSHG']\n",
      ">>>>>>>>>>>>>>>>>>>>000046_XSHE>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/bioinfo/lib/python3.9/site-packages/torch/autograd/__init__.py:197: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /opt/conda/conda-bld/pytorch_1670525539683/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n",
      "torch.Size([2, 42])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN(\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m---> 81\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m predictions\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtest(test_loader)\n\u001b[1;32m     83\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag_bin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlag_day\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_gcn_model_iteration_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 67\u001b[0m, in \u001b[0;36mGCN.fit\u001b[0;34m(self, train_loader, val_loader, num_epochs, patience)\u001b[0m\n\u001b[1;32m     65\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(inputs, graph_input)\n\u001b[1;32m     66\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 67\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters(), max_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     69\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/bioinfo/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/anaconda3/envs/bioinfo/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your PyTorch model is defined as before\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # stock_info = sys.argv[0]\n",
    "    # lag_bin = int(sys.argv[1])\n",
    "    # lag_day = int(sys.argv[2])\n",
    "    # bin_num = int(sys.argv[3])\n",
    "    # random_state_here = int(sys.argv[4])\n",
    "    # test_set_size = float(sys.argv[5])\n",
    "    lag_bin = 3\n",
    "    lag_day = 3\n",
    "    num_nodes = (int(lag_bin)+1)*(int(lag_day)+1)\n",
    "    forecast_days = 15\n",
    "    bin_num=24\n",
    "    random_state_here = 88\n",
    "    mape_list = []\n",
    "    data_dir = './data/volume/0308/'\n",
    "    files =file_name('./data/')\n",
    "    stocks_info = sorted(list(set(s.split('_25')[0] for s in files)))\n",
    "    print(stocks_info)\n",
    "    for stock_info in stocks_info[0:2]:\n",
    "        print(f'>>>>>>>>>>>>>>>>>>>>{stock_info}>>>>>>>>>>>>>>>>>>>>>>>')\n",
    "        data_dir1 = f'{data_dir}{stock_info}_{lag_bin}_{lag_day}'\n",
    "        test_set_size = bin_num*forecast_days\n",
    "        K = 5\n",
    "        inputs_data = np.load(f'{data_dir1}_inputs.npy', allow_pickle=True)\n",
    "        inputs_data = [[[torch.tensor(x, dtype=torch.float64) for x in sublist] for sublist in list1] for list1 in inputs_data]\n",
    "        array_data = np.array(inputs_data)\n",
    "        inputs = np.reshape(array_data, (len(inputs_data), num_nodes,-1))\n",
    "        targets = np.load(f'{data_dir1}_output.npy', allow_pickle=True).astype(np.float64)\n",
    "        graph_input = np.load(f'{data_dir1}_graph_input.npy', allow_pickle=True).astype(np.float64)\n",
    "        graph_input = np.array([graph_input] * inputs.shape[0])\n",
    "        graph_features = np.load(f'{data_dir1}_graph_coords.npy', allow_pickle=True).astype(np.float64)\n",
    "        graph_features = np.array([graph_features] * inputs.shape[0])\n",
    "\n",
    "        trainInputs, testInputs, traingraphInput, testgraphInput, traingraphFeature, testgraphFeature, trainTargets, testTargets = train_test_split(inputs, graph_input, graph_features, targets, test_size=test_set_size, \n",
    "                                                     random_state=random_state_here)\n",
    "        testInputs = normalize(testInputs)\n",
    "        # testInputs = test_inputs\n",
    "        inputsK, targetsK = k_fold_split(trainInputs, trainTargets, K)\n",
    "\n",
    "        mape_list = []\n",
    "\n",
    "        test_dataset = TensorDataset(torch.tensor(testInputs), torch.tensor(testgraphInput), torch.tensor(testTargets))\n",
    "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "        K = 5  # Number of folds\n",
    "        for k in range(K):\n",
    "            torch.manual_seed(0)  # Set a random seed for reproducibility\n",
    "\n",
    "            trainInputsAll, trainTargets, valInputsAll, valTargets = merge_splits(inputsK, targetsK, k, K)\n",
    "\n",
    "            trainGraphInput = traingraphInput[0:trainInputsAll.shape[0], :]\n",
    "            trainGraphFeatureInput = traingraphFeature[0:trainInputsAll.shape[0], :]\n",
    "\n",
    "            valGraphInput = traingraphInput[0:valInputsAll.shape[0], :]\n",
    "            valGraphFeatureInput = traingraphFeature[0:valInputsAll.shape[0], :]\n",
    "\n",
    "            trainInputs = normalize(trainInputsAll[:, :])\n",
    "            valInputs = normalize(valInputsAll[:, :])\n",
    "\n",
    "            # Assuming trainInputs, trainGraphInput, trainGraphFeatureInput, trainTargets are PyTorch tensors\n",
    "            train_dataset = TensorDataset(torch.tensor(trainInputs), torch.tensor(trainGraphInput),torch.tensor(trainTargets))\n",
    "            val_dataset = TensorDataset(torch.tensor(valInputs), torch.tensor(valGraphInput),torch.tensor(valTargets))\n",
    "\n",
    "            # train_dataset = TensorDataset(torch.tensor(trainInputs, dtype=torch.float32), torch.tensor(trainGraphInput, dtype=torch.float32), torch.tensor(trainGraphFeatureInput, dtype=torch.float32), torch.tensor(trainTargets, dtype=torch.float32))\n",
    "            # val_dataset = TensorDataset(torch.tensor(valInputs, dtype=torch.float32), torch.tensor(valGraphInput, dtype=torch.float32), torch.tensor(valGraphFeatureInput, dtype=torch.float32), torch.tensor(valTargets, dtype=torch.float32))\n",
    "\n",
    "            train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=50, shuffle=False)\n",
    "\n",
    "        \n",
    "            model = GCN(7,8,1)\n",
    "            print()\n",
    "            model.fit(train_loader, val_loader)\n",
    "            predictions=model.test(test_loader)\n",
    "            torch.save(model.state_dict(), f'models/{stock_info}_{lag_bin}_{lag_day}_gcn_model_iteration_{k}.pt')\n",
    "    \n",
    "            print()\n",
    "            print('Fold number:', k)\n",
    "\n",
    "            new_predictions = np.array([item.detach().numpy() for item in predictions]).flatten()\n",
    "            MAPE = []\n",
    "\n",
    "            MAPE.append(mean_absolute_percentage_error(testTargets[:], new_predictions[:]))\n",
    "            print(MAPE)\n",
    "            testTargets0 = list(testTargets)\n",
    "\n",
    "            res = {\n",
    "                'testTargets': testTargets0,\n",
    "                'new_predictions': new_predictions\n",
    "            }\n",
    "\n",
    "            res_df = pd.DataFrame(res)\n",
    "            res_df.to_csv(f'./result/{stock_info}_{lag_bin}_{lag_day}_res_test_MAPE{k}.csv', index=False)\n",
    "\n",
    "            print('MAPE = ', np.array(MAPE).mean())\n",
    "            MAPE_mean = np.array(MAPE).mean()\n",
    "            mape_list.append(MAPE)\n",
    "\n",
    "        print('-')\n",
    "        print('mape score = ', mape_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "686a4eb2-4c6f-4b71-b27f-bf65e3674129",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.random.randint(0,10,size=50*16*16).reshape([50,16,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1503d15a-4f3b-4ad1-bfee-fdaff6b32678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 600, 2])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(torch.stack([np.nonzero(t)for t in torch.unbind( torch.randn(10,20,30),dim=0)],dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4b18b6ad-7689-4e40-889e-29fc2440ef5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def int_to_one_hot(integer, num_classes):\n",
    "    one_hot = torch.nn.functional.one_hot(torch.tensor(integer - 1), num_classes=num_classes)\n",
    "    return one_hot\n",
    "\n",
    "# 例子：将整数编码 5 转换为 one-hot 编码\n",
    "integer_code = 5\n",
    "num_classes = 24  # 一天被划分为 24 个小时\n",
    "time_one_hot = int_to_one_hot(integer_code, num_classes)\n",
    "\n",
    "print(time_one_hot.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4968f-0cb6-4226-9613-cd69b9422d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e59b134b-611f-4062-904a-87b08567dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def one_hot_encoding(i, total_classes):\n",
    "    one_hot_vector = np.zeros(total_classes)\n",
    "    one_hot_vector[i] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "# 示例：生成长度为10的One-Hot向量，其中索引为3的位置是1，其他位置是0\n",
    "index = 3\n",
    "total_classes = 16\n",
    "result = one_hot_encoding(index, total_classes)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "958fba21-0bd3-450b-9498-2fb82a3cd550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.74049304 0.2683107  0.64684136 0.48311667 0.77103438 0.65039313\n",
      "  0.72921997 0.32415868 0.06038467 0.90408672 0.72370617 0.53347065\n",
      "  0.42896676 0.66994356 0.83883116 0.50870367]\n",
      " [0.00256826 0.07413307 0.94638582 0.86008728 0.98315507 0.90569552\n",
      "  0.81407539 0.28489578 0.09129948 0.7321216  0.53827818 0.50693083\n",
      "  0.82056561 0.54649232 0.7315669  0.38931277]\n",
      " [0.28372526 0.99687045 0.55981915 0.78662249 0.32212174 0.74443956\n",
      "  0.15220498 0.28171196 0.70329487 0.5579942  0.70249792 0.57378471\n",
      "  0.11665191 0.91947194 0.51315786 0.10236673]\n",
      " [0.63889845 0.44305818 0.53023973 0.82083926 0.24213653 0.13071741\n",
      "  0.94463156 0.14474002 0.61855058 0.34781547 0.78347262 0.32049134\n",
      "  0.14708563 0.66103614 0.16192767 0.14915083]\n",
      " [0.05886012 0.96334302 0.05970044 0.29037624 0.13125891 0.01666517\n",
      "  0.8223141  0.81990527 0.17862031 0.24181944 0.06319064 0.12500831\n",
      "  0.84252535 0.45658616 0.55880523 0.55723651]\n",
      " [0.73654614 0.62155648 0.19919113 0.94459622 0.63661815 0.11880613\n",
      "  0.16613741 0.55388569 0.12480164 0.09262199 0.92285943 0.09987285\n",
      "  0.75744888 0.35223478 0.60142136 0.96831499]\n",
      " [0.28708771 0.01078129 0.62070058 0.82117462 0.53703659 0.62766885\n",
      "  0.51207461 0.86804995 0.80196064 0.66076231 0.40614612 0.18246629\n",
      "  0.6829667  0.33215279 0.72845281 0.06700568]\n",
      " [0.83546937 0.28922117 0.88789772 0.44065017 0.40229796 0.1383436\n",
      "  0.26103753 0.66797271 0.12700842 0.35936922 0.90464612 0.16218381\n",
      "  0.53858791 0.06434952 0.0790059  0.0773995 ]\n",
      " [0.57834996 0.46861726 0.98555572 0.16317134 0.8365532  0.31640019\n",
      "  0.70969397 0.11568114 0.68061751 0.74510305 0.63618076 0.96330269\n",
      "  0.67366467 0.80624817 0.40166714 0.21194675]\n",
      " [0.17227078 0.98984268 0.03599855 0.81575405 0.26675859 0.05850047\n",
      "  0.05850897 0.09330126 0.61251919 0.81167443 0.05731941 0.77651729\n",
      "  0.36009856 0.29545394 0.26624337 0.67322524]\n",
      " [0.66026991 0.38462816 0.04693087 0.75977408 0.27126093 0.0968747\n",
      "  0.22421119 0.48443578 0.98568157 0.6880417  0.37157206 0.70757245\n",
      "  0.75659555 0.62482224 0.89158868 0.18598101]\n",
      " [0.22797302 0.15072159 0.04085763 0.24887479 0.83138612 0.08181184\n",
      "  0.1946516  0.01316729 0.4683104  0.09524852 0.17537738 0.07139556\n",
      "  0.55688253 0.29734849 0.12497595 0.9827467 ]\n",
      " [0.70927426 0.144742   0.51682168 0.67702802 0.36035871 0.66680725\n",
      "  0.98559591 0.47259555 0.61644156 0.16099727 0.99415315 0.34936764\n",
      "  0.68638492 0.92861682 0.64474966 0.75523697]\n",
      " [0.72757187 0.27461974 0.53040689 0.42948145 0.12590623 0.13134424\n",
      "  0.38749557 0.20598243 0.16032168 0.99568799 0.18184582 0.22437074\n",
      "  0.40112116 0.41262396 0.17892597 0.41258226]\n",
      " [0.28182515 0.97685136 0.22257515 0.39779537 0.44484208 0.53902453\n",
      "  0.18092088 0.17213674 0.57475044 0.32923623 0.86982435 0.3902121\n",
      "  0.46085136 0.16621549 0.55929182 0.78075021]\n",
      " [0.06106333 0.40563647 0.3658274  0.44601216 0.54943237 0.79101998\n",
      "  0.57289059 0.31747433 0.67808474 0.87795921 0.29052987 0.92297668\n",
      "  0.45098078 0.07912308 0.54098867 0.41659506]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 生成随机16x16矩阵\n",
    "A = np.random.rand(16, 16)\n",
    "\n",
    "print(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f9e7db00-6cf2-4a5a-838f-643c9db39008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74049304 0.00256826 0.28372526 0.63889845 0.05886012 0.73654614\n",
      " 0.28708771 0.83546937 0.57834996 0.17227078 0.66026991 0.22797302\n",
      " 0.70927426 0.72757187 0.28182515 0.06106333]\n",
      "[0.2683107  0.07413307 0.99687045 0.44305818 0.96334302 0.62155648\n",
      " 0.01078129 0.28922117 0.46861726 0.98984268 0.38462816 0.15072159\n",
      " 0.144742   0.27461974 0.97685136 0.40563647]\n",
      "[0.64684136 0.94638582 0.55981915 0.53023973 0.05970044 0.19919113\n",
      " 0.62070058 0.88789772 0.98555572 0.03599855 0.04693087 0.04085763\n",
      " 0.51682168 0.53040689 0.22257515 0.3658274 ]\n",
      "[0.48311667 0.86008728 0.78662249 0.82083926 0.29037624 0.94459622\n",
      " 0.82117462 0.44065017 0.16317134 0.81575405 0.75977408 0.24887479\n",
      " 0.67702802 0.42948145 0.39779537 0.44601216]\n",
      "[0.77103438 0.98315507 0.32212174 0.24213653 0.13125891 0.63661815\n",
      " 0.53703659 0.40229796 0.8365532  0.26675859 0.27126093 0.83138612\n",
      " 0.36035871 0.12590623 0.44484208 0.54943237]\n",
      "[0.65039313 0.90569552 0.74443956 0.13071741 0.01666517 0.11880613\n",
      " 0.62766885 0.1383436  0.31640019 0.05850047 0.0968747  0.08181184\n",
      " 0.66680725 0.13134424 0.53902453 0.79101998]\n",
      "[0.72921997 0.81407539 0.15220498 0.94463156 0.8223141  0.16613741\n",
      " 0.51207461 0.26103753 0.70969397 0.05850897 0.22421119 0.1946516\n",
      " 0.98559591 0.38749557 0.18092088 0.57289059]\n",
      "[0.32415868 0.28489578 0.28171196 0.14474002 0.81990527 0.55388569\n",
      " 0.86804995 0.66797271 0.11568114 0.09330126 0.48443578 0.01316729\n",
      " 0.47259555 0.20598243 0.17213674 0.31747433]\n",
      "[0.06038467 0.09129948 0.70329487 0.61855058 0.17862031 0.12480164\n",
      " 0.80196064 0.12700842 0.68061751 0.61251919 0.98568157 0.4683104\n",
      " 0.61644156 0.16032168 0.57475044 0.67808474]\n",
      "[0.90408672 0.7321216  0.5579942  0.34781547 0.24181944 0.09262199\n",
      " 0.66076231 0.35936922 0.74510305 0.81167443 0.6880417  0.09524852\n",
      " 0.16099727 0.99568799 0.32923623 0.87795921]\n",
      "[0.72370617 0.53827818 0.70249792 0.78347262 0.06319064 0.92285943\n",
      " 0.40614612 0.90464612 0.63618076 0.05731941 0.37157206 0.17537738\n",
      " 0.99415315 0.18184582 0.86982435 0.29052987]\n",
      "[0.53347065 0.50693083 0.57378471 0.32049134 0.12500831 0.09987285\n",
      " 0.18246629 0.16218381 0.96330269 0.77651729 0.70757245 0.07139556\n",
      " 0.34936764 0.22437074 0.3902121  0.92297668]\n",
      "[0.42896676 0.82056561 0.11665191 0.14708563 0.84252535 0.75744888\n",
      " 0.6829667  0.53858791 0.67366467 0.36009856 0.75659555 0.55688253\n",
      " 0.68638492 0.40112116 0.46085136 0.45098078]\n",
      "[0.66994356 0.54649232 0.91947194 0.66103614 0.45658616 0.35223478\n",
      " 0.33215279 0.06434952 0.80624817 0.29545394 0.62482224 0.29734849\n",
      " 0.92861682 0.41262396 0.16621549 0.07912308]\n",
      "[0.83883116 0.7315669  0.51315786 0.16192767 0.55880523 0.60142136\n",
      " 0.72845281 0.0790059  0.40166714 0.26624337 0.89158868 0.12497595\n",
      " 0.64474966 0.17892597 0.55929182 0.54098867]\n",
      "[0.50870367 0.38931277 0.10236673 0.14915083 0.55723651 0.96831499\n",
      " 0.06700568 0.0773995  0.21194675 0.67322524 0.18598101 0.9827467\n",
      " 0.75523697 0.41258226 0.78075021 0.41659506]\n"
     ]
    }
   ],
   "source": [
    "e_concat_list=[]\n",
    "for i in range(16):\n",
    "    a=A[:,i]\n",
    "    print(a)\n",
    "    e_concat_list.append(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "6416e154-42dd-4976-92af-50578bc537c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_attentional_mechanism_input(Wh):\n",
    "    # Wh.shape (N, out_feature)\n",
    "    # self.a.shape (2 * out_feature, 1)\n",
    "    # Wh1&2.shape (N, 1)\n",
    "    # e.shape (N, N)\n",
    "    E=[]\n",
    "    for i in range(16):\n",
    "        a=A[:,i].unsqueeze(1)\n",
    "        Wh1 = torch.matmul(Wh, a[:8, :])\n",
    "        Wh2 = torch.matmul(Wh, a[8:, :])\n",
    "        # broadcast add\n",
    "        e= Wh1 + Wh2.T\n",
    "        E.append(e[i,:])\n",
    "        E_matrix = torch.stack(E, dim=0)\n",
    "    return E_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "53eaead4-5c5c-46ee-8257-347fb63974b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor(np.random.rand(16, 16))\n",
    "B = torch.tensor(np.random.rand(16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "44ba9959-9855-4fb1-86d5-20180123e0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "e=_prepare_attentional_mechanism_input(B)\n",
    "print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "5c5d1c1e-9bf1-43dc-bcdf-4ab36a61e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nn.Parameter(torch.empty(size=(2*8, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "3075c6ec-7c6c-4ef2-b3fa-8a05ec1b0bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 5.5813e-11],\n",
       "        [ 3.0628e-41],\n",
       "        [-8.8168e+12],\n",
       "        [ 6.5540e-01],\n",
       "        [ 1.6507e-14],\n",
       "        [ 1.2486e+00],\n",
       "        [ 1.0065e+27],\n",
       "        [ 1.1304e+00],\n",
       "        [ 6.1175e-01],\n",
       "        [-1.3547e+00],\n",
       "        [-3.4584e+24],\n",
       "        [ 8.7174e-01],\n",
       "        [-1.8568e-02],\n",
       "        [ 1.3618e+00],\n",
       "        [ 2.0452e-05],\n",
       "        [ 1.4018e+00]], requires_grad=True)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9c349d9b-2a26-4a6f-b1dc-e50e58b87b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fdf84-6fbf-4b77-bf2f-c7c878601bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo",
   "language": "python",
   "name": "bioinfo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
